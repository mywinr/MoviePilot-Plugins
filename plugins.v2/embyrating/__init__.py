import time
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from xml.dom import minidom
import platform
import threading
import json

import pytz
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from watchdog.events import FileSystemEventHandler
from watchdog.observers.polling import PollingObserver

from app.plugins.embyrating.DoubanHelper import DoubanHelper

from app.core.config import settings
from app.core.event import eventmanager, Event
from app.core.metainfo import MetaInfoPath
from app.chain.media import MediaChain
from app.schemas import FileItem
from app.schemas.types import EventType, MediaType
from app.plugins import _PluginBase
from app.log import logger
from app.schemas import NotificationType


class NFOFileHandler(FileSystemEventHandler):
    """NFOæ–‡ä»¶ç›‘æ§å¤„ç†å™¨"""

    def __init__(self, emby_rating_instance):
        super().__init__()
        self.emby_rating = emby_rating_instance

    def on_created(self, event):
        """æ–‡ä»¶åˆ›å»ºäº‹ä»¶"""
        if event.is_directory:
            return

        file_path = Path(event.src_path)

        # åªå¤„ç†.nfoæ–‡ä»¶
        if file_path.suffix.lower() != '.nfo':
            return

        # è¿‡æ»¤æ‰ä¸€äº›ä¸éœ€è¦çš„æ–‡ä»¶
        filename = file_path.name.lower()
        if filename in ['fanart.nfo', 'poster.nfo', 'banner.nfo', 'thumb.nfo']:
            return

        logger.info(f"æ£€æµ‹åˆ°æ–°NFOæ–‡ä»¶: {file_path}")

        # ç›´æ¥å¤„ç†æ–‡ä»¶ï¼Œä¸ä½¿ç”¨çº¿ç¨‹æ± 
        try:
            self.emby_rating._handle_new_nfo_file(file_path)
        except Exception as e:
            logger.error(f"å¤„ç†NFOæ–‡ä»¶å¤±è´¥: {str(e)}")


class EmbyRating(_PluginBase):
    # æ’ä»¶åç§°
    plugin_name = "Embyè¯„åˆ†ç®¡ç†"
    # æ’ä»¶æè¿°
    plugin_desc = "ä¿®æ”¹Embyåª’ä½“è¯„åˆ†ï¼Œæ”¯æŒè±†ç“£è¯„åˆ†å’ŒTMDBè¯„åˆ†åˆ‡æ¢"
    # æ’ä»¶å›¾æ ‡
    plugin_icon = "https://raw.githubusercontent.com/DzAvril/MoviePilot-Plugins/main/icons/emby_rating.png"
    # æ’ä»¶ç‰ˆæœ¬
    plugin_version = "1.6"
    # æ’ä»¶ä½œè€…
    plugin_author = "DzAvril"
    # ä½œè€…ä¸»é¡µ
    author_url = "https://github.com/DzAvril"
    # æ’ä»¶é…ç½®é¡¹IDå‰ç¼€
    plugin_config_prefix = "embyrating"
    # åŠ è½½é¡ºåº
    plugin_order = 1
    # å¯ä½¿ç”¨çš„ç”¨æˆ·çº§åˆ«
    auth_level = 1
    # æ”¯æŒçš„åª’ä½“æ–‡ä»¶æ‰©å±•å
    MEDIA_EXTENSIONS = {'.mkv', '.mp4', '.avi', '.mov', '.wmv', '.flv', '.webm', '.strm'}

    # ç§æœ‰å±æ€§
    senabled = False
    _cron = None
    _notify = False
    _onlyonce = False
    _rating_source = "tmdb"  # tmdb æˆ– douban
    _update_interval = 7  # è±†ç“£è¯„åˆ†æ›´æ–°é—´éš”ï¼ˆå¤©ï¼‰
    _auto_scrape = True  # æ˜¯å¦è‡ªåŠ¨åˆ®å‰Š
    _cache_enabled = True  # ç¼“å­˜åŠŸèƒ½é»˜è®¤å¼€å¯
    _media_dirs = ""  # åª’ä½“ç›®å½•ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”
    _refresh_library = True  # æ˜¯å¦åœ¨æ›´æ–°NFOååˆ·æ–°åª’ä½“åº“
    _douban_cookie = ""  # è±†ç“£cookieé…ç½®
    _file_monitor_enabled = False  # æ˜¯å¦å¯ç”¨æ–‡ä»¶ç›‘æ§

    # å†å²è®°å½•æ–‡ä»¶è·¯å¾„
    _history_file = None

    # å®šæ—¶å™¨
    _scheduler: Optional[BackgroundScheduler] = None

    # æ–‡ä»¶ç›‘æ§ç›¸å…³
    _file_observers = []
    _monitor_thread = None
    _monitor_stop_event = None

    # è¯„åˆ†ç¼“å­˜ {media_key: {"rating": float, "last_update": timestamp}}
    _rating_cache: Dict[str, Dict] = {}

    # è±†ç“£åŠ©æ‰‹
    _douban_helper = None

    # å¤„ç†ç»“æœæ”¶é›†å™¨ï¼Œç”¨äºæ‰¹é‡é€šçŸ¥
    _processing_results: List[Dict] = []
    # å¤±è´¥ç»“æœæ”¶é›†å™¨
    _failed_results: List[Dict] = []
    # è·³è¿‡ç»“æœæ”¶é›†å™¨
    _skipped_results: List[Dict] = []

    # åœæ­¢æ ‡å¿—ï¼Œç”¨äºä¸­æ–­é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡
    _should_stop = False

    def __choose_observer(self, force_polling=False):
        """
        é€‰æ‹©æœ€ä¼˜çš„ç›‘æ§æ¨¡å¼
        :param force_polling: æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨è½®è¯¢æ¨¡å¼ï¼ˆé€‚ç”¨äºæœ‰å¤§é‡è½¯è¿æ¥çš„ç›®å½•ï¼‰
        """
        if force_polling:
            logger.info("å¼ºåˆ¶ä½¿ç”¨ PollingObserver ç›‘æ§æ¨¡å¼")
            return PollingObserver()

        system = platform.system()

        try:
            if system == "Linux":
                from watchdog.observers.inotify import InotifyObserver
                logger.debug("ä½¿ç”¨ InotifyObserver ç›‘æ§æ¨¡å¼")
                return InotifyObserver()
            elif system == "Darwin":
                from watchdog.observers.fsevents import FSEventsObserver
                logger.debug("ä½¿ç”¨ FSEventsObserver ç›‘æ§æ¨¡å¼")
                return FSEventsObserver()
            elif system == "Windows":
                from watchdog.observers.read_directory_changes import WindowsApiObserver
                logger.debug("ä½¿ç”¨ WindowsApiObserver ç›‘æ§æ¨¡å¼")
                return WindowsApiObserver()
        except Exception as error:
            logger.warn(f"å¯¼å…¥æ¨¡å—é”™è¯¯ï¼š{error}ï¼Œå°†ä½¿ç”¨ PollingObserver ç›‘æ§ç›®å½•")

        logger.info("ä½¿ç”¨ PollingObserver ç›‘æ§æ¨¡å¼")
        return PollingObserver()

    def init_plugin(self, config: dict = None):
        """åˆå§‹åŒ–æ’ä»¶"""
        # åˆå§‹åŒ–å†å²è®°å½•æ–‡ä»¶è·¯å¾„
        if self._history_file is None:
            self._history_file = Path(self.get_data_path()) / "rating_history.json"

        # åœæ­¢ç°æœ‰ä»»åŠ¡
        self.stop_service()

        if config:
            self._enabled = config.get("enabled")
            self._cron = config.get("cron")
            self._notify = config.get("notify")
            self._onlyonce = config.get("onlyonce")
            self._rating_source = config.get("rating_source", "tmdb")
            self._update_interval = config.get("update_interval", 7)
            self._auto_scrape = config.get("auto_scrape", True)
            self._media_dirs = config.get("media_dirs", "")
            # æ¸…é™¤ç¼“å­˜çš„åª’ä½“ç›®å½•è§£æç»“æœ
            if hasattr(self, '_parsed_media_dirs'):
                delattr(self, '_parsed_media_dirs')
            self._refresh_library = config.get("refresh_library", True)
            self._douban_cookie = config.get("douban_cookie", "")
            self._file_monitor_enabled = config.get("file_monitor_enabled", False)
            self._douban_helper = DoubanHelper(user_cookie=self._douban_cookie)

        # åŠ è½½ç¼“å­˜æ•°æ®
        self._load_cache_data()


        # å¦‚æœæ’ä»¶å¯ç”¨ï¼Œå¯åŠ¨ç›¸å…³æœåŠ¡
        if self._enabled:
            # å¯åŠ¨å®šæ—¶ä»»åŠ¡
            if self._cron:
                try:
                    self._scheduler = BackgroundScheduler(timezone=settings.TZ)
                    self._scheduler.add_job(
                        func=self.update_all_ratings,
                        trigger=CronTrigger.from_crontab(self._cron),
                        id="emby_rating_update",
                        name="Embyè¯„åˆ†æ›´æ–°"
                    )
                    self._scheduler.start()
                    logger.info(f"Embyè¯„åˆ†æ›´æ–°å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨ï¼Œæ‰§è¡Œå‘¨æœŸï¼š{self._cron}")
                except Exception as e:
                    logger.error(f"å¯åŠ¨å®šæ—¶ä»»åŠ¡å¤±è´¥ï¼š{str(e)}")

            # å¯åŠ¨æ–‡ä»¶ç›‘æ§
            if self._file_monitor_enabled and self._rating_source == "douban":
                self._start_file_monitor()

            # å¦‚æœæ˜¯ä¸€æ¬¡æ€§è¿è¡Œ
            if self._onlyonce:
                logger.info("å¼€å§‹æ‰§è¡Œä¸€æ¬¡æ€§è¯„åˆ†æ›´æ–°ä»»åŠ¡...")
                self.update_all_ratings()

        logger.info("Embyè¯„åˆ†ç®¡ç†æ’ä»¶åˆå§‹åŒ–å®Œæˆ")

    def _save_history_record(self, record: Dict):
        """ä¿å­˜å†å²è®°å½•"""
        try:
            # è·å–ç°æœ‰å†å²è®°å½•
            history_data = self._load_history_records()
            
            # æ·»åŠ æ–°è®°å½•
            history_data.append(record)
            
            # ä¿æŒæœ€å¤š1000æ¡è®°å½•
            if len(history_data) > 1000:
                history_data = history_data[-1000:]
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(self._history_file, 'w', encoding='utf-8') as f:
                json.dump(history_data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {str(e)}")

    def _load_history_records(self) -> List[Dict]:
        """åŠ è½½å†å²è®°å½•"""
        try:
            if self._history_file.exists():
                with open(self._history_file, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    if not content:
                        # æ–‡ä»¶ä¸ºç©ºï¼Œè¿”å›ç©ºåˆ—è¡¨
                        return []
                    return json.loads(content)
            return []
        except json.JSONDecodeError as e:
            logger.error(f"å†å²è®°å½•JSONæ ¼å¼é”™è¯¯: {str(e)}")
            # å¤‡ä»½æŸåçš„æ–‡ä»¶
            try:
                backup_file = self._history_file.with_suffix('.json.backup')
                self._history_file.rename(backup_file)
                logger.info(f"å·²å¤‡ä»½æŸåçš„å†å²è®°å½•æ–‡ä»¶åˆ°: {backup_file}")
            except Exception as backup_e:
                logger.error(f"å¤‡ä»½æŸåæ–‡ä»¶å¤±è´¥: {str(backup_e)}")

            # åˆ›å»ºæ–°çš„ç©ºæ–‡ä»¶
            try:
                with open(self._history_file, 'w', encoding='utf-8') as f:
                    json.dump([], f, ensure_ascii=False, indent=2)
                logger.info("å·²åˆ›å»ºæ–°çš„ç©ºå†å²è®°å½•æ–‡ä»¶")
            except Exception as create_e:
                logger.error(f"åˆ›å»ºæ–°å†å²è®°å½•æ–‡ä»¶å¤±è´¥: {str(create_e)}")

            return []
        except Exception as e:
            logger.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {str(e)}")
            return []

    def _add_success_record(self, title: str, rating: float, source: str, media_type: str, file_path: str = None, directory_alias: str = None):
        """æ·»åŠ æˆåŠŸè®°å½•"""
        # ç¡®ä¿åª’ä½“ç±»å‹æ˜¯å­—ç¬¦ä¸²æ ¼å¼
        media_type_str = str(media_type) if media_type else "UNKNOWN"
        # ç§»é™¤å¯èƒ½çš„æšä¸¾å‰ç¼€ï¼Œåªä¿ç•™åŸºæœ¬ç±»å‹
        if "." in media_type_str:
            media_type_str = media_type_str.split(".")[-1].upper()
        elif media_type_str.upper() in ["MOVIE", "TV"]:
            media_type_str = media_type_str.upper()
        elif media_type_str in ["ç”µå½±", "ç”µè§†å‰§", "æœªçŸ¥"]:
            # å¤„ç†ä¸­æ–‡åª’ä½“ç±»å‹å€¼ï¼Œè½¬æ¢ä¸ºè‹±æ–‡
            media_type_mapping = {
                "ç”µå½±": "MOVIE",
                "ç”µè§†å‰§": "TV",
                "æœªçŸ¥": "UNKNOWN"
            }
            media_type_str = media_type_mapping[media_type_str]
        else:
            media_type_str = "UNKNOWN"

        # è·å–ç›®å½•åˆ«åï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„åˆ«åï¼Œå¦åˆ™é€šè¿‡è·¯å¾„åŒ¹é…ï¼‰
        if directory_alias is None:
            directory_alias = self._get_directory_alias(file_path) if file_path else None

        record = {
            "title": title,
            "rating": rating,
            "rating_source": source,
            "media_type": media_type_str,
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "description": f"è¯„åˆ†æ›´æ–°æˆåŠŸ: {rating} ({source})",
            "directory_alias": directory_alias
        }
        self._save_history_record(record)

    def _add_failed_record(self, title: str, reason: str, media_type: str, file_path: str = None, directory_alias: str = None):
        """æ·»åŠ å¤±è´¥è®°å½•"""
        # ç¡®ä¿åª’ä½“ç±»å‹æ˜¯å­—ç¬¦ä¸²æ ¼å¼
        media_type_str = str(media_type) if media_type else "UNKNOWN"
        # ç§»é™¤å¯èƒ½çš„æšä¸¾å‰ç¼€ï¼Œåªä¿ç•™åŸºæœ¬ç±»å‹
        if "." in media_type_str:
            media_type_str = media_type_str.split(".")[-1].upper()
        elif media_type_str.upper() in ["MOVIE", "TV"]:
            media_type_str = media_type_str.upper()
        elif media_type_str in ["ç”µå½±", "ç”µè§†å‰§", "æœªçŸ¥"]:
            # å¤„ç†ä¸­æ–‡åª’ä½“ç±»å‹å€¼ï¼Œè½¬æ¢ä¸ºè‹±æ–‡
            media_type_mapping = {
                "ç”µå½±": "MOVIE",
                "ç”µè§†å‰§": "TV",
                "æœªçŸ¥": "UNKNOWN"
            }
            media_type_str = media_type_mapping[media_type_str]
        else:
            media_type_str = "UNKNOWN"

        # è·å–ç›®å½•åˆ«åï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„åˆ«åï¼Œå¦åˆ™é€šè¿‡è·¯å¾„åŒ¹é…ï¼‰
        if directory_alias is None:
            directory_alias = self._get_directory_alias(file_path) if file_path else None

        record = {
            "title": title,
            "rating": None,
            "rating_source": self._rating_source,
            "media_type": media_type_str,
            "status": "error",
            "timestamp": datetime.now().isoformat(),
            "description": f"è¯„åˆ†æ›´æ–°å¤±è´¥: {reason}",
            "error_message": reason,
            "directory_alias": directory_alias
        }
        self._save_history_record(record)

    def _add_skipped_record(self, title: str, reason: str, media_type: str):
        """æ·»åŠ è·³è¿‡è®°å½•ï¼ˆä¸å†ä¿å­˜åˆ°å†å²è®°å½•æ–‡ä»¶ï¼‰"""
        # è·³è¿‡è®°å½•ä¸å†ä¿å­˜åˆ°å†å²è®°å½•ä¸­ï¼Œåªç”¨äºç»Ÿè®¡å’Œé€šçŸ¥
        logger.debug(f"è·³è¿‡è®°å½•ï¼ˆä¸ä¿å­˜åˆ°å†å²ï¼‰: {title} - {reason}")
        pass

    def _get_directory_alias(self, file_path: str) -> str:
        """æ ¹æ®æ–‡ä»¶è·¯å¾„è·å–ç›®å½•åˆ«å"""
        if not file_path or not self._media_dirs:
            return None

        try:
            # ç¼“å­˜è§£æç»“æœä»¥æé«˜æ•ˆç‡
            if not hasattr(self, '_parsed_media_dirs'):
                self._parsed_media_dirs = []
                for dir_config in self._media_dirs.split("\n"):
                    dir_config = dir_config.strip()
                    if not dir_config or "#" not in dir_config:
                        continue

                    parts = dir_config.split("#")
                    if len(parts) >= 3:
                        config_path = parts[0].strip()
                        alias = parts[2].strip()
                        if config_path and alias:
                            self._parsed_media_dirs.append((config_path, alias))

            # å¿«é€ŸåŒ¹é…
            file_path = str(file_path)
            for config_path, alias in self._parsed_media_dirs:
                if file_path.startswith(config_path):
                    return alias

            return None

        except Exception as e:
            logger.debug(f"è·å–ç›®å½•åˆ«åå¤±è´¥: {str(e)}")
            return None


    def get_state(self) -> bool:
        """è·å–æ’ä»¶è¿è¡ŒçŠ¶æ€"""
        return self._enabled

    def _update_config(self):
        """æ›´æ–°é…ç½®"""
        self.update_config({
            "enabled": self._enabled,
            "cron": self._cron,
            "notify": self._notify,
            "onlyonce": self._onlyonce,
            "rating_source": self._rating_source,
            "update_interval": self._update_interval,
            "auto_scrape": self._auto_scrape,
            "media_dirs": self._media_dirs,
            "refresh_library": self._refresh_library,
            "douban_cookie": self._douban_cookie,
            "file_monitor_enabled": self._file_monitor_enabled
        })

    def _cleanup_cache(self):
        """æ¸…ç†è¿‡æœŸå’Œæ— æ•ˆçš„ç¼“å­˜æ•°æ®"""
        try:
            current_time = time.time()
            # ç¼“å­˜æœ€å¤§ä¿ç•™æ—¶é—´ï¼ˆ2å€æ›´æ–°é—´éš”ï¼‰
            max_cache_age = self._update_interval * 24 * 3600 * 2

            # æ¸…ç†è¯„åˆ†ç¼“å­˜
            if self._rating_cache:
                expired_keys = []

                for cache_key, cache_data in self._rating_cache.items():
                    last_update = cache_data.get("last_update", 0)
                    # åˆ é™¤è¿‡æœŸçš„ç¼“å­˜æ¡ç›®
                    if current_time - last_update > max_cache_age:
                        expired_keys.append(cache_key)

                for key in expired_keys:
                    del self._rating_cache[key]

                if expired_keys:
                    logger.info(
                        f"æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸç¼“å­˜æ¡ç›®")

            # ä¿å­˜æ¸…ç†åçš„ç¼“å­˜
            self._save_cache_data()

        except Exception as e:
            logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥ï¼š{str(e)}")

    def _load_cache_data(self):
        """åŠ è½½ç¼“å­˜æ•°æ®"""
        try:
            cache_data = self.get_data("rating_cache")
            if cache_data:
                self._rating_cache = cache_data

            # åŠ è½½åç«‹å³æ¸…ç†
            self._cleanup_cache()

        except Exception as e:
            logger.error(f"åŠ è½½ç¼“å­˜æ•°æ®å¤±è´¥ï¼š{str(e)}")

    def _save_cache_data(self):
        """ä¿å­˜ç¼“å­˜æ•°æ®"""
        try:
            self.save_data("rating_cache", self._rating_cache)
        except Exception as e:
            logger.error(
                f"ä¿å­˜ç¼“å­˜æ•°æ®å¤±è´¥ï¼š{str(e)}")

    def get_media_key(self, title: str, year: Optional[int] = None,
                      media_type: MediaType = None) -> str:
        """ç”Ÿæˆåª’ä½“å”¯ä¸€æ ‡è¯†"""
        key_parts = [title]
        if year:
            key_parts.append(str(year))
        if media_type:
            key_parts.append(media_type.value)
        return "|".join(key_parts)



    def get_tmdb_rating_from_nfo(self, nfo_path: Path) -> Optional[float]:
        """ä»NFOæ–‡ä»¶ä¸­è·å–TMDBè¯„åˆ†"""
        try:
            tree = ET.parse(nfo_path)
            root = tree.getroot()

            # é¦–å…ˆå°è¯•ä»EmbyRatingæ ‡ç­¾ä¸­è·å–TMDBè¯„åˆ†
            emby_rating_elem = root.find("EmbyRating")
            if emby_rating_elem is not None:
                tmdb_elem = emby_rating_elem.find("tmdb")
                if tmdb_elem is not None and tmdb_elem.text:
                    return float(tmdb_elem.text)

            # å¦‚æœæ²¡æœ‰EmbyRatingæ ‡ç­¾ï¼Œå°è¯•ä»ä¼ ç»Ÿçš„ratingæ ‡ç­¾è·å–
            rating_elem = root.find("rating")
            if rating_elem is not None:
                rating_text = rating_elem.text
                if rating_text:
                    return float(rating_text)

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ratingï¼Œå°è¯•ä»uniqueidä¸­è·å–TMDB IDå¹¶æŸ¥è¯¢
            tmdb_id = None
            for uniqueid in root.findall("uniqueid"):
                if uniqueid.get("type") == "tmdb":
                    tmdb_id = uniqueid.text
                    break

            if tmdb_id:
                # è¿™é‡Œå¯ä»¥è°ƒç”¨TMDB APIè·å–è¯„åˆ†ï¼Œæš‚æ—¶è¿”å›None
                logger.info(
                    f"æ‰¾åˆ°TMDB ID: {tmdb_id}ï¼Œ"
                    f"éœ€è¦è°ƒç”¨APIè·å–è¯„åˆ†")
                return None

        except Exception as e:
            logger.error(
                f"è¯»å–NFOæ–‡ä»¶è¯„åˆ†å¤±è´¥ {nfo_path}: {str(e)}")

        return None

    def backup_tmdb_rating(self, nfo_path: Path, media_key: str):
        """å¤‡ä»½TMDBè¯„åˆ†åˆ°EmbyRatingæ ‡ç­¾"""
        try:
            # è¯»å–åŸå§‹æ–‡ä»¶å†…å®¹
            try:
                with open(nfo_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                try:
                    with open(nfo_path, 'r', encoding='gbk') as f:
                        content = f.read()
                except UnicodeDecodeError:
                    logger.error(
                        f"æ— æ³•è¯»å–NFOæ–‡ä»¶ç¼–ç : {nfo_path}")
                    return

            # è§£æXML
            try:
                root = ET.fromstring(content)
            except ET.ParseError as e:
                logger.error(
                    f"XMLè§£æå¤±è´¥: {nfo_path}, "
                    f"é”™è¯¯: {str(e)}")
                return

            # æ£€æŸ¥æ˜¯å¦å·²æœ‰EmbyRatingæ ‡ç­¾
            emby_rating_elem = root.find("EmbyRating")
            if emby_rating_elem is None:
                emby_rating_elem = ET.SubElement(root, "EmbyRating")
                logger.debug(f"åˆ›å»ºEmbyRatingæ ‡ç­¾")

            # æ£€æŸ¥æ˜¯å¦å·²æœ‰tmdbè¯„åˆ†
            tmdb_elem = emby_rating_elem.find("tmdb")
            if tmdb_elem is not None and tmdb_elem.text:
                logger.debug(
                    f"EmbyRatingæ ‡ç­¾ä¸­å·²æœ‰TMDBè¯„åˆ†: "
                    f"{tmdb_elem.text}")
                return

            # è·å–å½“å‰è¯„åˆ†
            current_rating = None

            # é¦–å…ˆå°è¯•ä»ä¼ ç»Ÿratingæ ‡ç­¾è·å–
            rating_elem = root.find("rating")
            if rating_elem is not None and rating_elem.text:
                try:
                    current_rating = float(rating_elem.text)
                except ValueError:
                    pass

            # ä¿å­˜TMDBè¯„åˆ†åˆ°EmbyRatingæ ‡ç­¾
            if tmdb_elem is None:
                tmdb_elem = ET.SubElement(emby_rating_elem, "tmdb")

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯„åˆ†ï¼Œè®°å½•ä¸º"none"ï¼Œè¡¨ç¤ºåŸæœ¬å°±æ²¡æœ‰è¯„åˆ†
            if current_rating is None:
                tmdb_elem.text = "none"
                logger.info(f"åŸNFOæ–‡ä»¶æ— è¯„åˆ†ï¼Œå¤‡ä»½ä¸ºnone: {nfo_path}")
            else:
                tmdb_elem.text = str(current_rating)
                logger.info(f"å¤‡ä»½TMDBè¯„åˆ†: {media_key} = {current_rating}")

            # æ·»åŠ æ›´æ–°æ—¶é—´
            update_elem = emby_rating_elem.find("update")
            if update_elem is None:
                update_elem = ET.SubElement(emby_rating_elem, "update")
            update_elem.text = datetime.now().strftime("%Y-%m-%d")

            # æ ¼å¼åŒ–XMLå¹¶ç›´æ¥ä¿å­˜
            try:
                xml_str = self.format_xml(root)
                with open(nfo_path, 'w', encoding='utf-8') as f:
                    f.write(xml_str)
                logger.debug(f"å¤‡ä»½æ“ä½œå®Œæˆ: {nfo_path}")
            except Exception as e:
                logger.error(
                    f"ä¿å­˜NFOæ–‡ä»¶å¤±è´¥: {nfo_path}, "
                    f"é”™è¯¯: {str(e)}")
        except Exception as e:
            logger.error(
                f"å¤‡ä»½TMDBè¯„åˆ†å¤±è´¥ {nfo_path}: {str(e)}")

    def get_douban_rating(self, title: str,
                          year: Optional[int] = None) -> Optional[float]:
        """è·å–è±†ç“£è¯„åˆ†"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            if self._cache_enabled:
                cache_key = self.get_media_key(title, year, MediaType.MOVIE)
                if cache_key in self._rating_cache:
                    cache_data = self._rating_cache[cache_key]
                    last_update = cache_data.get("last_update", 0)
                    # æ£€æŸ¥æ˜¯å¦åœ¨æ›´æ–°é—´éš”å†…
                    update_interval_seconds = self._update_interval * 24 * 3600
                    if time.time() - last_update < update_interval_seconds:
                        logger.info(
                            f"ä½¿ç”¨ç¼“å­˜è±†ç“£è¯„åˆ†: "
                            f"{title} = {cache_data['rating']}")
                        return cache_data["rating"]

            logger.debug(f"å¼€å§‹æœç´¢è±†ç“£è¯„åˆ†: {title}")
            found_title, subject_id, score = self._douban_helper.get_subject_id(title)

            if subject_id and score and score != "0":
                rating = float(score)

                logger.debug(f"è±†ç“£æœç´¢ç»“æœ: æ ‡é¢˜='{found_title}', ID={subject_id}, è¯„åˆ†={score}")

                # æ›´æ–°ç¼“å­˜
                if self._cache_enabled:
                    cache_key = self.get_media_key(
                        title, year, MediaType.MOVIE)
                    self._rating_cache[cache_key] = {
                        "rating": rating,
                        "last_update": time.time()
                    }

                logger.info(
                    f"è·å–è±†ç“£è¯„åˆ†æˆåŠŸ: {title} = {rating} (æ‰¾åˆ°: {found_title})")
                return rating
            else:
                logger.debug(f"è±†ç“£æœç´¢æ— ç»“æœ: æ ‡é¢˜='{found_title}', ID={subject_id}, è¯„åˆ†={score}")
                logger.warning(f"æœªæ‰¾åˆ°è±†ç“£è¯„åˆ†: {title}")
                return None

        except Exception as e:
            logger.error(
                f"è·å–è±†ç“£è¯„åˆ†å¤±è´¥ {title}: {str(e)}")
            import traceback
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return None

    def format_xml(self, root) -> str:
        """æ ¼å¼åŒ–XMLï¼Œé¿å…å¤šä½™çš„ç©ºè¡Œ"""
        try:
            # ä½¿ç”¨minidomæ ¼å¼åŒ–ï¼Œä½†å¤„ç†å¤šä½™çš„ç©ºè¡Œ
            xml_str = minidom.parseString(
                ET.tostring(root, encoding='unicode')
            ).toprettyxml(indent="  ")

            # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
            lines = xml_str.split('\n')
            formatted_lines = []

            for i, line in enumerate(lines):
                # ä¿ç•™éç©ºè¡Œ
                if line.strip():
                    formatted_lines.append(line)
                # å¯¹äºç©ºè¡Œï¼Œåªåœ¨ç‰¹å®šæƒ…å†µä¸‹ä¿ç•™
                elif i > 0 and i < len(lines) - 1:
                    # æ£€æŸ¥å‰åè¡Œæ˜¯å¦éƒ½æ˜¯æ ‡ç­¾
                    prev_line = lines[i-1].strip()
                    next_line = lines[i+1].strip()

                    # å¦‚æœå‰åéƒ½æ˜¯æ ‡ç­¾ï¼Œä¿ç•™ä¸€ä¸ªç©ºè¡Œ
                    if (prev_line.startswith('<') and prev_line.endswith('>') and
                            next_line.startswith('<') and next_line.endswith('>')):
                        formatted_lines.append('')

            return '\n'.join(formatted_lines)

        except Exception as e:
            logger.error(f"XMLæ ¼å¼åŒ–å¤±è´¥: {str(e)}")
            # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„tostring
            return ET.tostring(root, encoding='unicode', xml_declaration=True)

    def should_skip_rating_update(self, nfo_path: Path, rating_source: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡è¯„åˆ†æ›´æ–°ï¼ˆè·³è¿‡é€»è¾‘ï¼‰"""
        try:
            # TMDBè¯„åˆ†ä¸éœ€è¦æ£€æŸ¥æ›´æ–°æ—¶é—´ï¼Œå› ä¸ºå®ƒæ˜¯é™æ€æ•°æ®
            if rating_source == "tmdb":
                return False

            # åªå¯¹è±†ç“£è¯„åˆ†è¿›è¡Œæ›´æ–°æ—¶é—´æ£€æŸ¥
            if rating_source != "douban":
                return False

            # è¯»å–NFOæ–‡ä»¶
            try:
                with open(nfo_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                try:
                    with open(nfo_path, 'r', encoding='gbk') as f:
                        content = f.read()
                except UnicodeDecodeError:
                    return False

            # è§£æXML
            try:
                root = ET.fromstring(content)
            except ET.ParseError:
                return False

            # æŸ¥æ‰¾EmbyRatingæ ‡ç­¾
            emby_rating_elem = root.find("EmbyRating")
            if emby_rating_elem is None:
                return False

            # æ£€æŸ¥å½“å‰è¯„åˆ†æº
            current_source_elem = emby_rating_elem.find("rating_source")
            if current_source_elem is None or current_source_elem.text != rating_source:
                return False

            # æ£€æŸ¥æ›´æ–°æ—¶é—´
            update_elem = emby_rating_elem.find("update")
            if update_elem is None or not update_elem.text:
                return False

            try:
                last_update = datetime.strptime(update_elem.text, "%Y-%m-%d")
                days_since_update = (datetime.now() - last_update).days

                if days_since_update < self._update_interval:
                    logger.debug(
                        f"è·³è¿‡æ›´æ–°ï¼Œè·ç¦»ä¸Šæ¬¡æ›´æ–°ä»…{days_since_update}å¤© "
                        f"(é—´éš”è®¾ç½®: {self._update_interval}å¤©): {nfo_path}"
                    )
                    return True
            except ValueError:
                # å¦‚æœæ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œä¸è·³è¿‡æ›´æ–°
                return False

            return False

        except Exception as e:
            logger.debug(f"æ£€æŸ¥è·³è¿‡é€»è¾‘æ—¶å‡ºé”™: {str(e)}")
            return False

    def get_existing_douban_rating(self, nfo_path: Path) -> Optional[float]:
        """ä»NFOæ–‡ä»¶ä¸­è·å–å·²å­˜åœ¨çš„è±†ç“£è¯„åˆ†"""
        try:
            # è¯»å–NFOæ–‡ä»¶
            try:
                with open(nfo_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                try:
                    with open(nfo_path, 'r', encoding='gbk') as f:
                        content = f.read()
                except UnicodeDecodeError:
                    return None

            # è§£æXML
            try:
                root = ET.fromstring(content)
            except ET.ParseError:
                return None

            # æŸ¥æ‰¾EmbyRatingæ ‡ç­¾
            emby_rating_elem = root.find("EmbyRating")
            if emby_rating_elem is None:
                return None

            # è·å–è±†ç“£è¯„åˆ†
            douban_elem = emby_rating_elem.find("douban")
            if douban_elem is None or not douban_elem.text:
                return None

            # æ£€æŸ¥è¯„åˆ†æ˜¯å¦æœ‰æ•ˆ
            try:
                rating = float(douban_elem.text)
                if rating > 0:  # è¯„åˆ†åº”è¯¥å¤§äº0
                    return rating
            except ValueError:
                return None

            return None

        except Exception as e:
            logger.debug(f"è·å–NFOä¸­å·²å­˜åœ¨çš„è±†ç“£è¯„åˆ†æ—¶å‡ºé”™: {str(e)}")
            return None

    def is_existing_douban_rating_valid(self, nfo_path: Path) -> bool:
        """æ£€æŸ¥NFOä¸­å·²å­˜åœ¨çš„è±†ç“£è¯„åˆ†æ˜¯å¦æœ‰æ•ˆä¸”æœªè¿‡æœŸ"""
        try:
            # è¯»å–NFOæ–‡ä»¶
            try:
                with open(nfo_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                try:
                    with open(nfo_path, 'r', encoding='gbk') as f:
                        content = f.read()
                except UnicodeDecodeError:
                    return False

            # è§£æXML
            try:
                root = ET.fromstring(content)
            except ET.ParseError:
                return False

            # æŸ¥æ‰¾EmbyRatingæ ‡ç­¾
            emby_rating_elem = root.find("EmbyRating")
            if emby_rating_elem is None:
                return False

            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è±†ç“£è¯„åˆ†
            douban_elem = emby_rating_elem.find("douban")
            if douban_elem is None or not douban_elem.text:
                return False

            # æ£€æŸ¥è¯„åˆ†æ˜¯å¦æœ‰æ•ˆ
            try:
                rating = float(douban_elem.text)
                if rating <= 0:  # è¯„åˆ†åº”è¯¥å¤§äº0
                    return False
            except ValueError:
                return False

            # æ£€æŸ¥æ›´æ–°æ—¶é—´
            update_elem = emby_rating_elem.find("update")
            if update_elem is None or not update_elem.text:
                return False

            try:
                last_update = datetime.strptime(update_elem.text, "%Y-%m-%d")
                days_since_update = (datetime.now() - last_update).days

                # æ£€æŸ¥æ˜¯å¦åœ¨æ›´æ–°é—´éš”å†…
                if days_since_update < self._update_interval:
                    logger.debug(
                        f"NFOä¸­å·²å­˜åœ¨çš„è±†ç“£è¯„åˆ†æœªè¿‡æœŸ: "
                        f"è·ç¦»ä¸Šæ¬¡æ›´æ–°{days_since_update}å¤© "
                        f"(é—´éš”è®¾ç½®: {self._update_interval}å¤©)"
                    )
                    return True
            except ValueError:
                # å¦‚æœæ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè®¤ä¸ºè¯„åˆ†æ— æ•ˆ
                return False

            return False

        except Exception as e:
            logger.debug(f"æ£€æŸ¥NFOä¸­å·²å­˜åœ¨çš„è±†ç“£è¯„åˆ†æœ‰æ•ˆæ€§æ—¶å‡ºé”™: {str(e)}")
            return False

    def update_nfo_rating(self, nfo_path: Path, new_rating: float,
                          rating_source: str = "douban", title: str = None,
                          media_type: str = None):
        """æ›´æ–°NFOæ–‡ä»¶ä¸­çš„è¯„åˆ†ï¼ˆåŒ…å«è·³è¿‡æ£€æŸ¥ï¼‰"""
        try:
            logger.debug(
                f"å¼€å§‹æ›´æ–°NFOè¯„åˆ†: {nfo_path} = "
                f"{new_rating} ({rating_source})"
            )

            # è·³è¿‡é€»è¾‘æ£€æŸ¥
            if self.should_skip_rating_update(nfo_path, rating_source):
                logger.info(f"è·³è¿‡è¯„åˆ†æ›´æ–°: {nfo_path}")
                # è®°å½•è·³è¿‡çš„ç»“æœ
                if title and media_type:
                    self._skipped_results.append({
                        'title': title,
                        'reason': 'è·ç¦»ä¸Šæ¬¡æ›´æ–°æ—¶é—´è¿‡çŸ­',
                        'media_type': media_type
                    })
                return True

            # è°ƒç”¨ç›´æ¥æ›´æ–°æ–¹æ³•
            return self._update_nfo_rating_direct(nfo_path, new_rating, rating_source)

        except Exception as e:
            logger.error(f"æ›´æ–°NFOè¯„åˆ†å¤±è´¥ {nfo_path}: {str(e)}")
            import traceback
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return False

    def _update_nfo_rating_direct(self, nfo_path: Path, new_rating: float,
                                 rating_source: str = "douban"):
        """ç›´æ¥æ›´æ–°NFOæ–‡ä»¶ä¸­çš„è¯„åˆ†ï¼ˆä¸è¿›è¡Œè·³è¿‡æ£€æŸ¥ï¼‰"""
        try:
            # è¯»å–åŸå§‹æ–‡ä»¶å†…å®¹
            try:
                with open(nfo_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                try:
                    with open(nfo_path, 'r', encoding='gbk') as f:
                        content = f.read()
                except UnicodeDecodeError:
                    logger.error(
                        f"æ— æ³•è¯»å–NFOæ–‡ä»¶ç¼–ç : {nfo_path}"
                    )
                    return False

            # è§£æXML
            try:
                root = ET.fromstring(content)
            except ET.ParseError as e:
                logger.error(
                    f"XMLè§£æå¤±è´¥: {nfo_path}, "
                    f"é”™è¯¯: {str(e)}"
                )
                return False

            # æŸ¥æ‰¾æˆ–åˆ›å»ºEmbyRatingæ ‡ç­¾
            emby_rating_elem = root.find("EmbyRating")
            if emby_rating_elem is None:
                emby_rating_elem = ET.SubElement(root, "EmbyRating")
                logger.debug(f"åˆ›å»ºEmbyRatingæ ‡ç­¾")

            # å¤‡ä»½åŸå§‹TMDBè¯„åˆ†ï¼ˆå¦‚æœå­˜åœ¨ä¸”å½“å‰è¦æ›´æ–°ä¸ºè±†ç“£è¯„åˆ†ï¼‰
            if rating_source == "douban":
                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰tmdbå¤‡ä»½
                tmdb_elem = emby_rating_elem.find("tmdb")
                if tmdb_elem is None:
                    # å°è¯•ä»ä¼ ç»Ÿratingæ ‡ç­¾è·å–åŸå§‹è¯„åˆ†
                    traditional_rating_elem = root.find("rating")
                    if traditional_rating_elem is not None and traditional_rating_elem.text:
                        try:
                            original_rating = float(traditional_rating_elem.text)
                            # åªæœ‰å½“åŸå§‹è¯„åˆ†ä¸æ˜¯0ä¸”ä¸ç­‰äºå½“å‰è±†ç“£è¯„åˆ†æ—¶æ‰å¤‡ä»½
                            if original_rating > 0 and abs(original_rating - new_rating) > 0.1:
                                tmdb_elem = ET.SubElement(emby_rating_elem, "tmdb")
                                tmdb_elem.text = str(original_rating)
                                logger.info(f"å¤‡ä»½åŸå§‹TMDBè¯„åˆ†: {original_rating}")
                        except (ValueError, TypeError):
                            logger.debug("åŸå§‹ratingæ ‡ç­¾å€¼æ— æ•ˆï¼Œè·³è¿‡å¤‡ä»½")

            # æ›´æ–°å¯¹åº”è¯„åˆ†æºçš„è¯„åˆ†
            rating_elem = emby_rating_elem.find(rating_source)
            if rating_elem is None:
                rating_elem = ET.SubElement(emby_rating_elem, rating_source)
            rating_elem.text = str(new_rating)

            # æ·»åŠ æˆ–æ›´æ–°rating_sourceå­—æ®µ
            rating_source_elem = emby_rating_elem.find("rating_source")
            if rating_source_elem is None:
                rating_source_elem = ET.SubElement(emby_rating_elem, "rating_source")
            rating_source_elem.text = rating_source

            # æ›´æ–°ä¼ ç»Ÿratingæ ‡ç­¾ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
            traditional_rating_elem = root.find("rating")
            if traditional_rating_elem is None:
                traditional_rating_elem = ET.SubElement(root, "rating")
            traditional_rating_elem.text = str(new_rating)

            # æ·»åŠ æ›´æ–°æ—¶é—´
            update_elem = emby_rating_elem.find("update")
            if update_elem is None:
                update_elem = ET.SubElement(emby_rating_elem, "update")
            update_elem.text = datetime.now().strftime("%Y-%m-%d")

            # ä½¿ç”¨æ”¹è¿›çš„æ ¼å¼åŒ–æ–¹æ³•
            xml_str = self.format_xml(root)

            # ç›´æ¥å†™å…¥åŸæ–‡ä»¶
            try:
                with open(nfo_path, 'w', encoding='utf-8') as f:
                    f.write(xml_str)
                logger.info(
                    f"æ›´æ–°NFOè¯„åˆ†æˆåŠŸ: {nfo_path} = "
                    f"{new_rating} ({rating_source})"
                )

                return True

            except Exception as e:
                logger.error(
                    f"ä¿å­˜NFOæ–‡ä»¶å¤±è´¥: {nfo_path}, "
                    f"é”™è¯¯: {str(e)}"
                )
                return False

        except Exception as e:
            logger.error(
                f"æ›´æ–°NFOè¯„åˆ†å¤±è´¥ {nfo_path}: {str(e)}"
            )
            import traceback
            logger.debug(
                f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}"
            )
            return False

    def _get_media_servers_from_config(self) -> set:
        """ä»åª’ä½“ç›®å½•é…ç½®ä¸­è·å–æ‰€æœ‰æ¶‰åŠçš„åª’ä½“æœåŠ¡å™¨åç§°"""
        servers = set()
        if not self._media_dirs:
            return servers

        for dir_config in self._media_dirs.split("\n"):
            dir_config = dir_config.strip()
            if not dir_config:  # è·³è¿‡ç©ºè¡Œ
                continue
            if "#" in dir_config:
                # è§£æè·¯å¾„å’Œåª’ä½“æœåŠ¡å™¨åç§°
                _, server_part = dir_config.split("#", 1)
                server_name = server_part.strip()
                if server_name:
                    servers.add(server_name)

        return servers

    def _refresh_media_servers(self, server_names: set):
        """åˆ·æ–°æŒ‡å®šçš„åª’ä½“æœåŠ¡å™¨"""
        if not self._refresh_library or not server_names:
            return

        try:
            # è·å–æ¨¡å—ç®¡ç†å™¨
            from app.core.module import ModuleManager
            from app.schemas.types import ModuleType
            module_manager = ModuleManager()

            # è·å–æ‰€æœ‰åª’ä½“æœåŠ¡å™¨æ¨¡å—
            media_server_modules = list(
                module_manager.get_running_type_modules(ModuleType.MediaServer)
            )

            if not media_server_modules:
                logger.warning(f"æœªæ‰¾åˆ°å¯ç”¨çš„åª’ä½“æœåŠ¡å™¨æ¨¡å—")
                return

            # åˆ·æ–°æ¯ä¸ªæŒ‡å®šçš„åª’ä½“æœåŠ¡å™¨
            for server_name in server_names:
                target_module = None
                for module in media_server_modules:
                    try:
                        instances = module.get_instances()
                        if server_name in instances:
                            target_module = module
                            break
                    except Exception as e:
                        logger.debug(
                            f"æ£€æŸ¥æ¨¡å— {module.__class__.__name__} "
                            f"æ—¶å‡ºé”™: {str(e)}"
                        )
                        continue

                if not target_module:
                    logger.warning(
                        f"æœªæ‰¾åˆ°æŒ‡å®šçš„åª’ä½“æœåŠ¡å™¨: {server_name}"
                    )
                    continue

                # è·å–æœåŠ¡å™¨å®ä¾‹å¹¶åˆ·æ–°
                server_instance = target_module.get_instance(server_name)
                if not server_instance:
                    logger.warning(
                        f"æ— æ³•è·å–åª’ä½“æœåŠ¡å™¨å®ä¾‹: {server_name}"
                    )
                    continue

                if hasattr(server_instance, 'refresh_root_library'):
                    success = server_instance.refresh_root_library()
                    if success:
                        logger.info(
                            f"æˆåŠŸåˆ·æ–°åª’ä½“åº“: {server_name}"
                        )
                    else:
                        logger.warning(
                            f"åˆ·æ–°åª’ä½“åº“å¤±è´¥: {server_name}"
                        )
                else:
                    logger.warning(
                        f"åª’ä½“æœåŠ¡å™¨ {server_name} ä¸æ”¯æŒåˆ·æ–°åŠŸèƒ½"
                    )

        except Exception as e:
            logger.error(f"åˆ·æ–°åª’ä½“åº“å¤±è´¥: {str(e)}")

    def update_all_ratings(self):
        """æ›´æ–°æ‰€æœ‰åª’ä½“è¯„åˆ†"""
        logger.info(f"å¼€å§‹æ›´æ–°æ‰€æœ‰åª’ä½“è¯„åˆ†")

        # é‡ç½®åœæ­¢æ ‡å¿—
        self._should_stop = False

        # åˆå§‹åŒ–å¤„ç†ç»“æœæ”¶é›†å™¨
        self._processing_results = []
        self._failed_results = []
        self._skipped_results = []

        # è·å–åª’ä½“ç›®å½•åˆ—è¡¨å’Œå¯¹åº”çš„åˆ«å
        media_dirs = []
        if self._media_dirs:
            for dir_config in self._media_dirs.split("\n"):
                dir_config = dir_config.strip()
                if not dir_config:  # è·³è¿‡ç©ºè¡Œ
                    continue

                alias = None
                if "#" in dir_config:
                    # è§£æè·¯å¾„ã€åª’ä½“æœåŠ¡å™¨åç§°å’Œåˆ«å
                    parts = dir_config.split("#")
                    path_part = parts[0].strip()
                    # å¦‚æœæœ‰ç¬¬ä¸‰ä¸ªå‚æ•°ï¼Œé‚£å°±æ˜¯åˆ«å
                    if len(parts) >= 3:
                        alias = parts[2].strip() or None
                    media_dir = Path(path_part)
                else:
                    # æ²¡æœ‰æŒ‡å®šåª’ä½“æœåŠ¡å™¨ï¼Œåªä½¿ç”¨è·¯å¾„
                    media_dir = Path(dir_config.strip())

                if media_dir:
                    media_dirs.append((media_dir, alias))

        if not media_dirs:
            logger.warning(f"æœªé…ç½®åª’ä½“ç›®å½•")
            return

        # å¤„ç†æ¯ä¸ªåª’ä½“ç›®å½•
        for media_dir, alias in media_dirs:
            if self._should_stop:
                logger.info(f"æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œä¸­æ–­è¯„åˆ†æ›´æ–°ä»»åŠ¡")
                break

            if not media_dir.exists():
                logger.warning(f"åª’ä½“ç›®å½•ä¸å­˜åœ¨: {media_dir}")
                continue

            logger.info(f"å¤„ç†åª’ä½“ç›®å½•: {media_dir} (åˆ«å: {alias or 'æ— '})")
            self.process_media_directory(media_dir, alias)

        # å‘é€æ‰¹é‡é€šçŸ¥
        self._send_batch_notification()

        # ä¿å­˜ç¼“å­˜æ•°æ®
        self._save_cache_data()

        # æ¸…ç†è¿‡æœŸç¼“å­˜
        self._cleanup_cache()

        # æ‰¹é‡å¤„ç†å®Œæˆåï¼Œåˆ·æ–°æ‰€æœ‰æ¶‰åŠçš„åª’ä½“æœåŠ¡å™¨
        if self._refresh_library:
            server_names = self._get_media_servers_from_config()
            if server_names:
                logger.info(
                    f"å¼€å§‹åˆ·æ–°åª’ä½“æœåŠ¡å™¨: {', '.join(server_names)}"
                )
                self._refresh_media_servers(server_names)
            else:
                logger.debug(f"æœªé…ç½®éœ€è¦åˆ·æ–°çš„åª’ä½“æœåŠ¡å™¨")

        logger.info(f"è¯„åˆ†æ›´æ–°å®Œæˆ")

    def _send_batch_notification(self):
        """å‘é€æ±‡æ€»é€šçŸ¥"""
        if not self._notify:
            return

        try:
            # ç»Ÿè®¡å¤„ç†ç»“æœ
            success_count = len(self._processing_results)
            failed_count = len(self._failed_results)
            skipped_count = len(self._skipped_results)
            total_count = success_count + failed_count + skipped_count

            # å¦‚æœæ²¡æœ‰ä»»ä½•å¤„ç†ç»“æœï¼Œä¸å‘é€é€šçŸ¥
            if total_count == 0:
                return

            # æŒ‰è¯„åˆ†æºç»Ÿè®¡æˆåŠŸçš„æ›´æ–°
            douban_count = sum(
                1 for result in self._processing_results
                if result['source'] == 'douban'
            )
            tmdb_count = sum(
                1 for result in self._processing_results
                if result['source'] == 'tmdb'
            )

            # æŒ‰åª’ä½“ç±»å‹ç»Ÿè®¡æˆåŠŸçš„æ›´æ–°
            movie_count = sum(
                1 for result in self._processing_results
                if result['media_type'] == 'MOVIE'
            )
            tv_count = sum(
                1 for result in self._processing_results
                if result['media_type'] == 'TV'
            )

            # æŒ‰åª’ä½“ç±»å‹ç»Ÿè®¡å¤±è´¥çš„æ›´æ–°
            failed_movie_count = sum(
                1 for result in self._failed_results
                if result['media_type'] == 'MOVIE'
            )
            failed_tv_count = sum(
                1 for result in self._failed_results
                if result['media_type'] == 'TV'
            )

            # æŒ‰åª’ä½“ç±»å‹ç»Ÿè®¡è·³è¿‡çš„æ›´æ–°
            skipped_movie_count = sum(
                1 for result in self._skipped_results
                if result['media_type'] == 'MOVIE'
            )
            skipped_tv_count = sum(
                1 for result in self._skipped_results
                if result['media_type'] == 'TV'
            )

            # æ„å»ºé€šçŸ¥æ ‡é¢˜
            if failed_count == 0:
                title = "ğŸ¬ è¯„åˆ†æ›´æ–°å®Œæˆ"
            else:
                title = "ğŸ¬ è¯„åˆ†æ›´æ–°å®Œæˆï¼ˆéƒ¨åˆ†å¤±è´¥ï¼‰"

            # æ„å»ºé€šçŸ¥å†…å®¹
            text_parts = []

            # æ€»ä½“ç»Ÿè®¡
            total_movie_count = movie_count + failed_movie_count + skipped_movie_count
            total_tv_count = tv_count + failed_tv_count + skipped_tv_count

            if total_movie_count > 0 and total_tv_count > 0:
                text_parts.append(f"ğŸ“Š å…±å¤„ç† {total_count} éƒ¨å½±ç‰‡ï¼ˆğŸ¥ ç”µå½± {total_movie_count} éƒ¨ï¼ŒğŸ“º ç”µè§†å‰§ {total_tv_count} éƒ¨ï¼‰")
            elif total_movie_count > 0:
                text_parts.append(f"ğŸ“Š å…±å¤„ç† {total_count} éƒ¨ç”µå½±")
            elif total_tv_count > 0:
                text_parts.append(f"ğŸ“Š å…±å¤„ç† {total_count} éƒ¨ç”µè§†å‰§")
            else:
                text_parts.append(f"ğŸ“Š å…±å¤„ç† {total_count} éƒ¨å½±ç‰‡")

            if success_count > 0:
                # æˆåŠŸç»Ÿè®¡ - æŒ‰åª’ä½“ç±»å‹æ˜¾ç¤º
                success_parts = []
                if movie_count > 0:
                    success_parts.append(f"ğŸ¥ ç”µå½± {movie_count} éƒ¨")
                if tv_count > 0:
                    success_parts.append(f"ğŸ“º ç”µè§†å‰§ {tv_count} éƒ¨")

                if success_parts:
                    text_parts.append(f"âœ… æˆåŠŸæ›´æ–°ï¼š{' | '.join(success_parts)}")
                else:
                    text_parts.append(f"âœ… æˆåŠŸæ›´æ–° {success_count} éƒ¨")

                # æŒ‰è¯„åˆ†æºåˆ†ç±»æ˜¾ç¤º
                source_parts = []
                if douban_count > 0:
                    source_parts.append(f"è±†ç“£ {douban_count} éƒ¨")
                if tmdb_count > 0:
                    source_parts.append(f"TMDB {tmdb_count} éƒ¨")
                if source_parts:
                    text_parts.append(f"ğŸ“ˆ è¯„åˆ†æºï¼š{' | '.join(source_parts)}")

            if failed_count > 0:
                # å¤±è´¥ç»Ÿè®¡ - æŒ‰åª’ä½“ç±»å‹æ˜¾ç¤º
                failed_parts = []
                if failed_movie_count > 0:
                    failed_parts.append(f"ğŸ¥ ç”µå½± {failed_movie_count} éƒ¨")
                if failed_tv_count > 0:
                    failed_parts.append(f"ğŸ“º ç”µè§†å‰§ {failed_tv_count} éƒ¨")

                if failed_parts:
                    text_parts.append(f"âŒ å¤±è´¥ï¼š{' | '.join(failed_parts)}")
                else:
                    text_parts.append(f"âŒ å¤±è´¥ {failed_count} éƒ¨")

            if skipped_count > 0:
                # è·³è¿‡ç»Ÿè®¡ - æŒ‰åª’ä½“ç±»å‹æ˜¾ç¤º
                skipped_parts = []
                if skipped_movie_count > 0:
                    skipped_parts.append(f"ğŸ¥ ç”µå½± {skipped_movie_count} éƒ¨")
                if skipped_tv_count > 0:
                    skipped_parts.append(f"ğŸ“º ç”µè§†å‰§ {skipped_tv_count} éƒ¨")

                if skipped_parts:
                    text_parts.append(f"â­ï¸ è·³è¿‡ï¼š{' | '.join(skipped_parts)}")
                else:
                    text_parts.append(f"â­ï¸ è·³è¿‡ {skipped_count} éƒ¨")

            text = "\n".join(text_parts)

            # å‘é€é€šçŸ¥
            self.post_message(
                mtype=NotificationType.MediaServer,
                title=title,
                text=text
            )

            logger.info(f"å‘é€æ±‡æ€»é€šçŸ¥ï¼š{title}")
            logger.debug(f"é€šçŸ¥å†…å®¹ï¼š{text}")

        except Exception as e:
            logger.error(f"å‘é€æ‰¹é‡é€šçŸ¥å¤±è´¥ï¼š{str(e)}")

        finally:
            # ä¿å­˜å¤„ç†ç»“æœåˆ°å†å²è®°å½•ï¼ˆä¸ä¿å­˜è·³è¿‡çš„è®°å½•ï¼‰
            for result in self._processing_results:
                self._add_success_record(
                    result['title'],
                    result['rating'],
                    result['source'],
                    result['media_type'],
                    result.get('file_path'),
                    result.get('directory_alias')
                )

            for result in self._failed_results:
                self._add_failed_record(
                    result['title'],
                    result['reason'],
                    result['media_type'],
                    result.get('file_path'),
                    result.get('directory_alias')
                )

            # æ¸…ç©ºå¤„ç†ç»“æœåˆ—è¡¨
            self._processing_results.clear()
            self._failed_results.clear()
            self._skipped_results.clear()

    @staticmethod
    def get_command() -> List[Dict[str, Any]]:
        """å®šä¹‰è¿œç¨‹æ§åˆ¶å‘½ä»¤"""
        return [
            {
                "cmd": "/embyrating_update",
                "event": EventType.PluginAction,
                "desc": "æ›´æ–°Embyè¯„åˆ†",
                "category": "åª’ä½“ç®¡ç†",
                "data": {"action": "update_ratings"}
            },
            {
                "cmd": "/embyrating_switch_tmdb",
                "event": EventType.PluginAction,
                "desc": "åˆ‡æ¢åˆ°TMDBè¯„åˆ†",
                "category": "åª’ä½“ç®¡ç†",
                "data": {"action": "switch_to_tmdb"}
            },
            {
                "cmd": "/embyrating_switch_douban",
                "event": EventType.PluginAction,
                "desc": "åˆ‡æ¢åˆ°è±†ç“£è¯„åˆ†",
                "category": "åª’ä½“ç®¡ç†",
                "data": {"action": "switch_to_douban"}
            }
        ]

    @eventmanager.register(EventType.PluginAction)
    def handle_commands(self, event: Event):
        """å¤„ç†è¿œç¨‹å‘½ä»¤"""
        if not self._enabled:
            return

        if not event or not event.event_data:
            return

        action = event.event_data.get("action")
        if not action:
            return

        if action == "update_ratings":
            self.update_all_ratings()
        elif action == "switch_to_tmdb":
            self._rating_source = "tmdb"
            self._update_config()
            self.update_all_ratings()
        elif action == "switch_to_douban":
            self._rating_source = "douban"
            self._update_config()
            self.update_all_ratings()

    def get_history_endpoint(self, limit: int = 20, offset: int = 0) -> Dict[str, Any]:
        """
        APIç«¯ç‚¹ï¼šè·å–å†å²è®°å½•ï¼Œæ”¯æŒåˆ†é¡µå‚æ•°
        """
        try:
            return self.get_history_api(limit, offset)
        except Exception as e:
            logger.error(f"è·å–å†å²è®°å½•ç«¯ç‚¹å¤±è´¥: {str(e)}")
            return {"success": False, "message": str(e)}

    def clear_history_endpoint(self) -> Dict[str, Any]:
        """
        APIç«¯ç‚¹ï¼šæ¸…é™¤å†å²è®°å½•
        """
        try:
            return self.clear_history_api()
        except Exception as e:
            logger.error(f"æ¸…é™¤å†å²è®°å½•ç«¯ç‚¹å¤±è´¥: {str(e)}")
            return {"success": False, "message": str(e)}

    def get_api(self) -> List[Dict[str, Any]]:
        """æ³¨å†Œæ’ä»¶API"""
        return [
            {
                "path": "/history",
                "endpoint": self.get_history_endpoint,
                "methods": ["GET"],
                "auth": "bear",
                "summary": "è·å–è¯„åˆ†æ›´æ–°å†å²è®°å½•",
                "description": "è¿”å›è¯„åˆ†æ›´æ–°çš„å†å²è®°å½•ï¼Œæ”¯æŒåˆ†é¡µå‚æ•°(limit, offset)"
            },
            {
                "path": "/history",
                "endpoint": self.clear_history_endpoint,
                "methods": ["DELETE"],
                "auth": "bear",
                "summary": "æ¸…é™¤è¯„åˆ†æ›´æ–°å†å²è®°å½•",
                "description": "åˆ é™¤æ‰€æœ‰è¯„åˆ†æ›´æ–°å†å²è®°å½•"
            },
            {
                "path": "/config",
                "endpoint": self.get_config_api,
                "methods": ["GET"],
                "auth": "bear",
                "summary": "è·å–æ’ä»¶é…ç½®",
                "description": "è¿”å›å½“å‰æ’ä»¶é…ç½®ä¿¡æ¯"
            },
            {
                "path": "/config",
                "endpoint": self.set_config_api,
                "methods": ["POST"],
                "auth": "bear",
                "summary": "è®¾ç½®æ’ä»¶é…ç½®",
                "description": "ä¿å­˜æ’ä»¶é…ç½®ä¿¡æ¯"
            },
            {
                "path": "/run",
                "endpoint": self.run_now_api,
                "methods": ["POST"],
                "auth": "bear",
                "summary": "ç«‹å³è¿è¡Œè¯„åˆ†æ›´æ–°",
                "description": "ç«‹å³æ‰§è¡Œä¸€æ¬¡è¯„åˆ†æ›´æ–°ä»»åŠ¡"
            },
            {
                "path": "/monitor_dirs",
                "endpoint": self.get_monitor_dirs_api,
                "methods": ["GET"],
                "auth": "bear",
                "summary": "è·å–ç›‘æ§ç›®å½•",
                "description": "è¿”å›å½“å‰ç›‘æ§çš„ç›®å½•åˆ—è¡¨"
            }
        ]



    def get_monitor_dirs_api(self):
        """è·å–ç›‘æ§ç›®å½•API"""
        try:
            monitor_dirs = []
            if self._media_dirs:
                for dir_config in self._media_dirs.split("\n"):
                    dir_config = dir_config.strip()
                    if not dir_config:
                        continue
                    if "#" in dir_config:
                        path_part, server_part = dir_config.split("#", 1)
                        monitor_path = path_part.strip()
                        server_name = server_part.strip()
                    else:
                        monitor_path = dir_config.strip()
                        server_name = "æœªæŒ‡å®š"

                    monitor_dirs.append({
                        "path": monitor_path,
                        "server": server_name,
                        "exists": Path(monitor_path).exists()
                    })

            return {
                "success": True,
                "data": monitor_dirs
            }
        except Exception as e:
            logger.error(f"è·å–ç›‘æ§ç›®å½•å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": f"è·å–ç›‘æ§ç›®å½•å¤±è´¥: {str(e)}"
            }

    def get_history_api(self, limit: int = 20, offset: int = 0) -> Dict[str, Any]:
        """
        è·å–å†å²è®°å½•APIç«¯ç‚¹ï¼Œæ”¯æŒåˆ†é¡µå‚æ•°

        Args:
            limit: æ¯é¡µè®°å½•æ•°ï¼Œé»˜è®¤20ï¼Œæœ€å¤§100
            offset: åç§»é‡ï¼Œé»˜è®¤0

        Returns:
            åŒ…å«å†å²è®°å½•æ•°æ®å’Œåˆ†é¡µä¿¡æ¯çš„å­—å…¸
        """
        try:
            # ç¡®ä¿å‚æ•°æ˜¯æ•´æ•°ç±»å‹
            try:
                limit = int(limit) if limit is not None else 20
                offset = int(offset) if offset is not None else 0
            except (ValueError, TypeError) as e:
                logger.warning(f"å‚æ•°è½¬æ¢å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å€¼")
                limit = 20
                offset = 0

            # é™åˆ¶å‚æ•°èŒƒå›´ï¼Œé˜²æ­¢æ€§èƒ½é—®é¢˜
            limit = min(max(limit, 10), 100)  # æœ€å°10æ¡ï¼Œæœ€å¤§100æ¡
            offset = max(offset, 0)  # offsetä¸èƒ½ä¸ºè´Ÿæ•°

            # åŠ è½½å†å²è®°å½•
            all_history = self._load_history_records()

            # åå‘æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
            all_history.reverse()

            # è®¡ç®—æ€»æ•°å’Œåˆ†é¡µä¿¡æ¯
            total = len(all_history)

            # åˆ†é¡µæ•°æ®
            history_data = all_history[offset:offset + limit]

            # è®¡ç®—æ˜¯å¦è¿˜æœ‰æ›´å¤šè®°å½•
            has_more = (offset + len(history_data)) < total

            return {
                "success": True,
                "data": history_data,
                "pagination": {
                    "total": total,
                    "offset": offset,
                    "limit": limit,
                    "has_more": has_more,
                    "current_count": len(history_data)
                }
            }
        except Exception as e:
            logger.error(f"è·å–å†å²è®°å½•å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": f"è·å–å†å²è®°å½•å¤±è´¥: {str(e)}"
            }

    def clear_history_api(self) -> Dict[str, Any]:
        """æ¸…é™¤å†å²è®°å½•APIç«¯ç‚¹"""
        try:
            # åˆ›å»ºç©ºçš„JSONæ•°ç»„å¹¶å†™å…¥æ–‡ä»¶
            with open(self._history_file, 'w', encoding='utf-8') as f:
                json.dump([], f, ensure_ascii=False, indent=2)

            logger.info("å†å²è®°å½•å·²æ¸…é™¤")

            return {
                "success": True,
                "message": "å†å²è®°å½•å·²æ¸…é™¤"
            }
        except Exception as e:
            logger.error(f"æ¸…é™¤å†å²è®°å½•å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": f"æ¸…é™¤å†å²è®°å½•å¤±è´¥: {str(e)}"
            }

    def get_config_api(self):
        """è·å–é…ç½®API"""
        try:
            config_data = {
                "enabled": self._enabled,
                "cron": self._cron,
                "notify": self._notify,
                "onlyonce": self._onlyonce,
                "rating_source": self._rating_source,
                "update_interval": self._update_interval,
                "auto_scrape": self._auto_scrape,
                "media_dirs": self._media_dirs,
                "refresh_library": self._refresh_library,
                "douban_cookie": self._douban_cookie,
                "file_monitor_enabled": self._file_monitor_enabled
            }
            
            return {
                "success": True,
                "data": config_data
            }
        except Exception as e:
            return {
                "success": False,
                "message": f"è·å–é…ç½®å¤±è´¥: {str(e)}"
            }

    def set_config_api(self, config_data: dict):
        """è®¾ç½®é…ç½®API"""
        try:
            # æ›´æ–°é…ç½®
            if "enabled" in config_data:
                self._enabled = config_data["enabled"]
            if "cron" in config_data:
                self._cron = config_data["cron"]
            if "notify" in config_data:
                self._notify = config_data["notify"]
            if "onlyonce" in config_data:
                self._onlyonce = config_data["onlyonce"]
            if "rating_source" in config_data:
                self._rating_source = config_data["rating_source"]
            if "update_interval" in config_data:
                self._update_interval = config_data["update_interval"]
            if "auto_scrape" in config_data:
                self._auto_scrape = config_data["auto_scrape"]
            if "media_dirs" in config_data:
                self._media_dirs = config_data["media_dirs"]
            if "refresh_library" in config_data:
                self._refresh_library = config_data["refresh_library"]
            if "douban_cookie" in config_data:
                self._douban_cookie = config_data["douban_cookie"]
            if "file_monitor_enabled" in config_data:
                self._file_monitor_enabled = config_data["file_monitor_enabled"]
            
            # æ›´æ–°è±†ç“£åŠ©æ‰‹
            self._douban_helper = DoubanHelper(user_cookie=self._douban_cookie)
            
            # ä¿å­˜é…ç½®
            self._update_config()
            
            # é‡æ–°åˆå§‹åŒ–æ’ä»¶
            self.init_plugin({
                "enabled": self._enabled,
                "cron": self._cron,
                "notify": self._notify,
                "onlyonce": self._onlyonce,
                "rating_source": self._rating_source,
                "update_interval": self._update_interval,
                "auto_scrape": self._auto_scrape,
                "media_dirs": self._media_dirs,
                "refresh_library": self._refresh_library,
                "douban_cookie": self._douban_cookie,
                "file_monitor_enabled": self._file_monitor_enabled
            })
            
            return {
                "success": True,
                "message": "é…ç½®ä¿å­˜æˆåŠŸ"
            }
        except Exception as e:
            return {
                "success": False,
                "message": f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}"
            }

    def run_now_api(self):
        """ç«‹å³è¿è¡ŒAPI"""
        try:
            # å¯åŠ¨ä¸€ä¸ªæ–°çº¿ç¨‹æ¥æ‰§è¡Œè¯„åˆ†æ›´æ–°ï¼Œé¿å…é˜»å¡APIå“åº”
            import threading
            thread = threading.Thread(target=self.update_all_ratings)
            thread.start()
            
            return {
                "success": True,
                "message": "è¯„åˆ†æ›´æ–°ä»»åŠ¡å·²å¯åŠ¨"
            }
        except Exception as e:
            return {
                "success": False,
                "message": f"å¯åŠ¨ä»»åŠ¡å¤±è´¥: {str(e)}"
            }

    def switch_rating_source(self, source: str):
        """åˆ‡æ¢è¯„åˆ†æºAPI"""
        if source not in ["tmdb", "douban"]:
            return {"success": False, "message": "æ— æ•ˆçš„è¯„åˆ†æº"}

        self._rating_source = source
        self._update_config()
        self.update_all_ratings()

        return {"success": True, "message": f"å·²åˆ‡æ¢åˆ°{source}è¯„åˆ†"}

    def get_form(self) -> Tuple[Optional[List[dict]], Dict[str, Any]]:
        """è¿”å›Vueç»„ä»¶é…ç½®"""
        return None, {
            "enabled": self._enabled,
            "cron": self._cron,
            "notify": self._notify,
            "onlyonce": self._onlyonce,
            "rating_source": self._rating_source,
            "update_interval": self._update_interval,
            "auto_scrape": self._auto_scrape,
            "media_dirs": self._media_dirs,
            "refresh_library": self._refresh_library,
            "douban_cookie": self._douban_cookie,
            "file_monitor_enabled": self._file_monitor_enabled
        }

    def get_page(self) -> Optional[List[dict]]:
        """Vueæ¨¡å¼ä¸ä½¿ç”¨Vuetifyé¡µé¢å®šä¹‰"""
        return None

    @staticmethod
    def get_render_mode() -> Tuple[str, Optional[str]]:
        """è·å–æ’ä»¶æ¸²æŸ“æ¨¡å¼"""
        return "vue", "dist/assets"

    def stop_service(self):
        """åœæ­¢æ’ä»¶"""
        # è®¾ç½®åœæ­¢æ ‡å¿—ï¼Œä¸­æ–­æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
        self._should_stop = True
        logger.info(f"è®¾ç½®åœæ­¢æ ‡å¿—ï¼Œæ­£åœ¨ä¸­æ–­è¿è¡Œä¸­çš„ä»»åŠ¡...")

        # åœæ­¢æ–‡ä»¶ç›‘æ§
        try:
            self._stop_file_monitor()
        except Exception as e:
            logger.error(f"åœæ­¢æ–‡ä»¶ç›‘æ§å¤±è´¥ï¼š{str(e)}")

        # åœæ­¢ç›‘æ§çº¿ç¨‹
        try:
            self._stop_monitor_thread()
        except Exception as e:
            logger.error(f"åœæ­¢ç›‘æ§çº¿ç¨‹å¤±è´¥ï¼š{str(e)}")

        try:
            if self._scheduler:
                self._scheduler.remove_all_jobs()
                if self._scheduler.running:
                    self._scheduler.shutdown()
                self._scheduler = None
        except Exception as e:
            logger.error(f"åœæ­¢å®šæ—¶ä»»åŠ¡å¤±è´¥ï¼š{str(e)}")
            
        self._should_stop = False

    def _stop_monitor_thread(self):
        """åœæ­¢ç›‘æ§çº¿ç¨‹"""
        try:
            # è®¾ç½®åœæ­¢äº‹ä»¶
            if self._monitor_stop_event:
                self._monitor_stop_event.set()
                logger.debug("å·²è®¾ç½®ç›‘æ§çº¿ç¨‹åœæ­¢äº‹ä»¶")

            # ç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸ
            if self._monitor_thread and self._monitor_thread.is_alive():
                logger.info("æ­£åœ¨ç­‰å¾…ç›‘æ§çº¿ç¨‹åœæ­¢...")
                self._monitor_thread.join(timeout=5.0)

                if self._monitor_thread.is_alive():
                    logger.warning("ç›‘æ§çº¿ç¨‹åœ¨5ç§’å†…æœªèƒ½åœæ­¢")
                else:
                    logger.info("ç›‘æ§çº¿ç¨‹å·²æˆåŠŸåœæ­¢")
            # æ£€æŸ¥çº¿ç¨‹æ˜¯å¦å­˜åœ¨ä½†æœªå¯åŠ¨çš„æƒ…å†µ
            elif self._monitor_thread and not self._monitor_thread.is_alive():
                # çº¿ç¨‹å­˜åœ¨ä½†æœªå¯åŠ¨æˆ–å·²ç»“æŸï¼Œç›´æ¥æ¸…ç†
                logger.debug("ç›‘æ§çº¿ç¨‹å·²å­˜åœ¨ä½†æœªå¯åŠ¨æˆ–å·²ç»“æŸï¼Œç›´æ¥æ¸…ç†")

            # æ¸…ç†çº¿ç¨‹å¯¹è±¡
            self._monitor_thread = None
            self._monitor_stop_event = None

        except Exception as e:
            logger.error(f"åœæ­¢ç›‘æ§çº¿ç¨‹æ—¶å‡ºé”™: {str(e)}")



    def process_media_directory(self, media_dir: Path, directory_alias: str = None):
        """å¤„ç†åª’ä½“ç›®å½•"""
        try:
            # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
            if not media_dir.exists():
                logger.warning(f"åª’ä½“ç›®å½•ä¸å­˜åœ¨: {media_dir}")
                return

            # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„NFOæ–‡ä»¶
            processed_shows = set()  # è®°å½•å·²å¤„ç†çš„ç”µè§†å‰§ï¼Œé¿å…é‡å¤å¤„ç†

            # ç»Ÿè®¡ç›®å½•ä¸­çš„æ–‡ä»¶
            total_files = 0
            media_files = 0
            nfo_files = 0

            # éå†ç›®å½•æŸ¥æ‰¾åª’ä½“æ–‡ä»¶
            for item in media_dir.rglob("*"):
                if self._should_stop:
                    logger.info(f"æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œä¸­æ–­åª’ä½“ç›®å½•å¤„ç†")
                    break

                if item.is_file():
                    total_files += 1
                    if item.suffix.lower() == '.nfo':
                        nfo_files += 1
                    elif item.suffix.lower() in self.MEDIA_EXTENSIONS:
                        media_files += 1

                if item.is_file() and item.suffix.lower() in self.MEDIA_EXTENSIONS:
                    logger.debug(f"å‘ç°åª’ä½“æ–‡ä»¶: {item}")
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç”µè§†å‰§ç»“æ„
                    if self._is_tv_show_structure(item):
                        logger.debug(f"è¯†åˆ«ä¸ºç”µè§†å‰§ç»“æ„: {item}")
                        # å¤„ç†ç”µè§†å‰§
                        show_root = self._get_tv_show_root(item)
                        if show_root and show_root not in processed_shows:
                            logger.info(f"å¼€å§‹å¤„ç†ç”µè§†å‰§: {show_root}")
                            processed_shows.add(show_root)
                            self._process_tv_show(show_root, directory_alias)
                        elif show_root in processed_shows:
                            logger.debug(f"ç”µè§†å‰§å·²å¤„ç†ï¼Œè·³è¿‡: {show_root}")
                    else:
                        logger.debug(f"è¯†åˆ«ä¸ºç”µå½±: {item}")
                        # å¤„ç†ç”µå½±
                        nfo_path = item.with_suffix('.nfo')
                        if not nfo_path.exists():
                            logger.debug(f"NFOæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•åˆ®å‰Š: {nfo_path}")
                            # å°è¯•åˆ®å‰Šï¼Œä¼ é€’ç›®æ ‡åª’ä½“æ–‡ä»¶
                            if not self.scrape_media_if_needed(item.parent, False, item):
                                logger.debug(f"åˆ®å‰Šå¤±è´¥æˆ–è·³è¿‡: {item}")
                                continue
                            # é‡æ–°æ£€æŸ¥NFOæ–‡ä»¶
                            if not nfo_path.exists():
                                logger.warning(
                                    f"åˆ®å‰Šåä»æœªæ‰¾åˆ°NFOæ–‡ä»¶: {nfo_path}"
                                )
                                continue
                        # å¤„ç†NFOæ–‡ä»¶
                        self.process_nfo_file(nfo_path, MediaType.MOVIE, directory_alias)

            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            logger.info(f"ç›®å½•ç»Ÿè®¡ - æ€»æ–‡ä»¶: {total_files}, åª’ä½“æ–‡ä»¶: {media_files}, NFOæ–‡ä»¶: {nfo_files}")
            if media_files == 0:
                logger.warning(f"ç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½•åª’ä½“æ–‡ä»¶: {media_dir}")
            if nfo_files == 0:
                logger.warning(f"ç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½•NFOæ–‡ä»¶: {media_dir}")

        except Exception as e:
            logger.error(f"å¤„ç†åª’ä½“ç›®å½•å¤±è´¥ {media_dir}: {str(e)}")

    def _is_tv_show_structure(self, media_file: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç”µè§†å‰§ç»“æ„"""
        try:
            # æ£€æŸ¥è·¯å¾„ç»“æ„ï¼Œç”µè§†å‰§é€šå¸¸æœ‰ å‰§é›†å/å­£/é›† çš„ç»“æ„
            parts = media_file.parts
            if len(parts) >= 3:
                # æ£€æŸ¥æ˜¯å¦æœ‰å­£çš„ç›®å½•ç»“æ„
                for part in parts:
                    if ('season' in part.lower() or
                            part.lower().startswith('s') and part[1:].isdigit()):
                        return True
            return False
        except Exception:
            return False

    def _get_tv_show_root(self, media_file: Path) -> Optional[Path]:
        """è·å–ç”µè§†å‰§æ ¹ç›®å½•"""
        try:
            current = media_file.parent
            while current and current.name:
                # æ£€æŸ¥æ˜¯å¦æœ‰tvshow.nfoæ–‡ä»¶
                tvshow_nfo = current / "tvshow.nfo"
                if tvshow_nfo.exists():
                    return current
                current = current.parent
            return None
        except Exception:
            return None

    def _process_tv_show(self, show_root: Path, directory_alias: str = None):
        """å¤„ç†ç”µè§†å‰§ï¼Œæ›´æ–°tvshow.nfoæ–‡ä»¶è¯„åˆ†"""
        try:
            tvshow_nfo = show_root / "tvshow.nfo"

            # å¦‚æœtvshow.nfoä¸å­˜åœ¨ï¼Œå°è¯•åˆ®å‰Š
            if not tvshow_nfo.exists():
                logger.info(f"æœªæ‰¾åˆ°tvshow.nfoæ–‡ä»¶ï¼Œå°è¯•åˆ®å‰Š: {show_root}")

                # æ£€æŸ¥æ˜¯å¦ä¸ºç”µè§†å‰§ç›®å½•ï¼ˆåŒ…å«å­£ç›®å½•ç»“æ„ï¼‰
                if self._is_tv_show_directory(show_root):
                    # å°è¯•åˆ®å‰Š
                    if self.scrape_media_if_needed(show_root, is_tv_show=True):
                        # é‡æ–°æ£€æŸ¥tvshow.nfoæ–‡ä»¶
                        if not tvshow_nfo.exists():
                            logger.warning(f"åˆ®å‰Šåä»æœªæ‰¾åˆ°tvshow.nfoæ–‡ä»¶: {show_root}")
                            return
                    else:
                        logger.warning(f"åˆ®å‰Šå¤±è´¥: {show_root}")
                        return
                else:
                    logger.warning(f"ç›®å½•ç»“æ„ä¸ç¬¦åˆç”µè§†å‰§æ ¼å¼ï¼Œè·³è¿‡: {show_root}")
                    return

            logger.info(f"ä½¿ç”¨ç»Ÿä¸€æ–¹æ³•å¤„ç†ç”µè§†å‰§NFO: {tvshow_nfo}")
            self.process_nfo_file(tvshow_nfo, MediaType.TV, directory_alias)



        except Exception as e:
            logger.error(f"å¤„ç†ç”µè§†å‰§å¤±è´¥ {show_root}: {str(e)}")
            # æ·»åŠ åˆ°å¤±è´¥ç»“æœ
            self._failed_results.append({
                'title': f"{show_root.name} (ç”µè§†å‰§)" if show_root else "æœªçŸ¥ç”µè§†å‰§",
                'reason': f'å¤„ç†å¼‚å¸¸: {str(e)}',
                'media_type': 'TV'
            })

    def _is_tv_show_directory(self, directory: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç”µè§†å‰§ç›®å½•"""
        try:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å­£ç›®å½•ç»“æ„
            season_dirs = []
            for item in directory.iterdir():
                if item.is_dir():
                    # æ£€æŸ¥æ˜¯å¦ä¸ºå­£ç›®å½•
                    if ('season' in item.name.lower() or
                        item.name.lower().startswith('s') and item[1:].isdigit()):
                        season_dirs.append(item)
            
            # å¦‚æœåŒ…å«å¤šä¸ªå­£ç›®å½•ï¼Œå¾ˆå¯èƒ½æ˜¯ç”µè§†å‰§æ ¹ç›®å½•
            if len(season_dirs) >= 1:
                logger.debug(f"å‘ç°å­£ç›®å½•ç»“æ„: {[d.name for d in season_dirs]}")
                return True
            
            # æ£€æŸ¥æ˜¯å¦ç›´æ¥åŒ…å«åª’ä½“æ–‡ä»¶ï¼ˆå¯èƒ½æ˜¯å­£ç›®å½•ï¼‰
            media_files = []
            for item in directory.iterdir():
                if item.is_file() and item.suffix.lower() in self.MEDIA_EXTENSIONS:
                    media_files.append(item)
            
            # å¦‚æœåŒ…å«åª’ä½“æ–‡ä»¶ä½†æ²¡æœ‰å­£ç›®å½•ï¼Œå¯èƒ½æ˜¯å­£ç›®å½•æˆ–ç”µå½±ç›®å½•
            if media_files:
                logger.debug(f"å‘ç°åª’ä½“æ–‡ä»¶ï¼Œå¯èƒ½æ˜¯å­£ç›®å½•æˆ–ç”µå½±ç›®å½•: {len(media_files)} ä¸ªæ–‡ä»¶")
                return False
            
            # å¦‚æœæ—¢æ²¡æœ‰å­£ç›®å½•ä¹Ÿæ²¡æœ‰åª’ä½“æ–‡ä»¶ï¼Œå¯èƒ½æ˜¯ç©ºçš„ç”µè§†å‰§ç›®å½•
            logger.debug(f"ç›®å½•ä¸ºç©ºæˆ–åªåŒ…å«å…¶ä»–æ–‡ä»¶ï¼Œå¯èƒ½æ˜¯ç©ºçš„ç”µè§†å‰§ç›®å½•")
            return True
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥ç”µè§†å‰§ç›®å½•ç»“æ„å¤±è´¥ {directory}: {str(e)}")
            return False

    def _get_first_season_rating(self, base_title: str, year: str) -> Optional[float]:
        """è·å–å‰§é›†è¯„åˆ†ï¼ˆä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€å­£è¯„åˆ†ï¼‰"""
        try:
            rating = self.get_douban_rating(base_title, year)
            if rating:
                logger.info(f"ç›´æ¥è·å–è±†ç“£è¯„åˆ†æˆåŠŸ: {base_title} = {rating}")
                return rating

            # å¦‚æœç›´æ¥è·å–å¤±è´¥ï¼Œå°è¯•ç”¨"ç¬¬ä¸€å­£"æ ¼å¼
            season_title_formats = [
                f"{base_title} ç¬¬ä¸€å­£",
                f"{base_title} ç¬¬ ä¸€ å­£",
                f"{base_title} Season 1",
                f"{base_title} S1",
                f"{base_title} S01"
            ]

            for season_title in season_title_formats:
                logger.info(f"å°è¯•å­£æ ¼å¼: {season_title}")
                rating = self.get_douban_rating(season_title, year)
                if rating:
                    logger.info(f"å­£æ ¼å¼è·å–è±†ç“£è¯„åˆ†æˆåŠŸ: {season_title} = {rating}")
                    return rating

            logger.warning(f"æ— æ³•è·å–è±†ç“£è¯„åˆ†: {base_title}")
            return None

        except Exception as e:
            logger.error(f"è·å–å‰§é›†è¯„åˆ†å¤±è´¥: {str(e)}")
            import traceback
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return None

    def _extract_title_from_tvshow_nfo(self, root) -> Optional[str]:
        """ä»tvshow.nfoçš„XMLæ ¹å…ƒç´ ä¸­æå–æ ‡é¢˜"""
        try:
            # å°è¯•å¤šç§æ ‡é¢˜å…ƒç´ 
            title_tags = ["title", "originaltitle", "sorttitle", "name", "showname"]

            for tag_name in title_tags:
                # ä½¿ç”¨ç®€å•çš„æŸ¥æ‰¾æ–¹æ³•
                elem = root.find(tag_name)
                if elem is not None and elem.text and elem.text.strip():
                    title = elem.text.strip()
                    logger.info(f"ä»{tag_name}å…ƒç´ è·å–æ ‡é¢˜: {title}")
                    return title

                # å¦‚æœç®€å•æŸ¥æ‰¾å¤±è´¥ï¼Œå°è¯•å¿½ç•¥å‘½åç©ºé—´çš„æŸ¥æ‰¾
                for child in root.iter():
                    if child.tag.lower().endswith(tag_name.lower()) and child.text and child.text.strip():
                        title = child.text.strip()
                        logger.info(f"ä»{child.tag}å…ƒç´ è·å–æ ‡é¢˜: {title}")
                        return title

            logger.warning(f"æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„æ ‡é¢˜å…ƒç´ ")
            return None

        except Exception as e:
            logger.error(f"æå–æ ‡é¢˜å¤±è´¥: {str(e)}")
            return None

    def find_elem_ignore_ns(self, root, tag_name):
        """åœ¨rootä¸‹æŸ¥æ‰¾å¿½ç•¥å‘½åç©ºé—´å’Œä¸å¯è§å­—ç¬¦çš„tag_nameå…ƒç´ ï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯"""
        found_elements = []
        logger.debug(f"å¼€å§‹æŸ¥æ‰¾å…ƒç´ : {tag_name}")

        for elem in root.iter():
            tag = elem.tag
            if tag.lower().strip().endswith(tag_name.lower()):
                found_elements.append(elem)
                logger.debug(f"å‘½ä¸­tag: {repr(tag)}")

        logger.debug(f"æŸ¥æ‰¾å®Œæˆï¼Œæ‰¾åˆ° {len(found_elements)} ä¸ª {tag_name} å…ƒç´ ")

        if found_elements:
            # è¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„å…ƒç´ 
            logger.debug(f"æ‰¾åˆ° {len(found_elements)} ä¸ª {tag_name} å…ƒç´ ï¼Œè¿”å›ç¬¬ä¸€ä¸ª")
            return found_elements[0]
        else:
            logger.debug(f"æœªæ‰¾åˆ°ä»»ä½• {tag_name} å…ƒç´ ")
            return None

    def process_nfo_file(self, nfo_path: Path, media_type: MediaType = MediaType.UNKNOWN, directory_alias: str = None):
        """å¤„ç†å•ä¸ªNFOæ–‡ä»¶ï¼Œå…¼å®¹å‘½åç©ºé—´"""
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            if self._should_stop:
                logger.info(f"æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œè·³è¿‡NFOæ–‡ä»¶å¤„ç†: {nfo_path}")
                return

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not nfo_path.exists():
                logger.warning(f"NFOæ–‡ä»¶ä¸å­˜åœ¨: {nfo_path}")
                return

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = nfo_path.stat().st_size
            if file_size == 0:
                logger.warning(f"NFOæ–‡ä»¶ä¸ºç©º: {nfo_path}")
                return

            logger.info(
                f"å¼€å§‹å¤„ç†NFOæ–‡ä»¶: {nfo_path} (å¤§å°: {file_size} bytes)")

            # å°è¯•è¯»å–æ–‡ä»¶å†…å®¹
            try:
                with open(nfo_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                logger.debug(f"æˆåŠŸè¯»å–NFOæ–‡ä»¶å†…å®¹ï¼Œé•¿åº¦: {len(content)}")
            except UnicodeDecodeError:
                try:
                    with open(nfo_path, 'r', encoding='gbk') as f:
                        content = f.read()
                    logger.debug(f"ä½¿ç”¨GBKç¼–ç æˆåŠŸè¯»å–NFOæ–‡ä»¶")
                except UnicodeDecodeError:
                    logger.error(f"NFOæ–‡ä»¶ç¼–ç æ— æ³•è¯†åˆ«: {nfo_path}")
                    return
                except Exception as e:
                    logger.error(
                        f"è¯»å–NFOæ–‡ä»¶å¤±è´¥: {nfo_path}, é”™è¯¯: {str(e)}")
                    return

            # è§£æXML
            try:
                root = ET.fromstring(content)
                logger.debug(f"æˆåŠŸè§£æXMLï¼Œæ ¹å…ƒç´ : {root.tag}")
            except ET.ParseError as e:
                logger.error(
                    f"XMLè§£æå¤±è´¥: {nfo_path}, é”™è¯¯: {str(e)}")
                return
            except Exception as e:
                logger.error(
                    f"XMLè§£æå¼‚å¸¸: {nfo_path}, é”™è¯¯: {str(e)}")
                return

            # è·å–åª’ä½“ä¿¡æ¯ï¼ˆå¿½ç•¥å‘½åç©ºé—´ï¼‰
            title_elem = self.find_elem_ignore_ns(root, "title")
            if title_elem is None:
                logger.warning(f"NFOæ–‡ä»¶ä¸­æœªæ‰¾åˆ°titleå…ƒç´ : {nfo_path}")
                # å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„æ ‡é¢˜å…ƒç´ 
                alt_title_elem = None
                for title_tag in ["originaltitle", "sorttitle", "name", "showname"]:
                    alt_title_elem = self.find_elem_ignore_ns(root, title_tag)
                    if alt_title_elem is not None and alt_title_elem.text:
                        logger.info(
                            f"ä½¿ç”¨æ›¿ä»£æ ‡é¢˜å…ƒç´  {title_tag}: {alt_title_elem.text}")
                        break
                if alt_title_elem and alt_title_elem.text:
                    title_elem = alt_title_elem
                else:
                    logger.warning(
                        f"NFOæ–‡ä»¶ç¼ºå°‘æœ‰æ•ˆæ ‡é¢˜ï¼Œå°è¯•ä»æ–‡ä»¶åæ¨æ–­: {nfo_path}")
                    # ä»æ–‡ä»¶åæ¨æ–­æ ‡é¢˜
                    filename = nfo_path.stem  # å»æ‰æ‰©å±•å
                    import re
                    title_from_filename = re.sub(
                        r'\s*\(\d{4}\)\s*.*$', '', filename)
                    title_from_filename = re.sub(
                        r'\s*-\s*\d+p.*$', '', title_from_filename)
                    title_from_filename = re.sub(
                        r'\s*-\s*2160p.*$', '', title_from_filename)
                    title_from_filename = title_from_filename.strip()
                    if title_from_filename:
                        logger.info(
                            f"ä»æ–‡ä»¶åæ¨æ–­æ ‡é¢˜: {title_from_filename}")
                        title_elem = ET.Element("title")
                        title_elem.text = title_from_filename
                    else:
                        logger.warning(
                            f"æ— æ³•ä»æ–‡ä»¶åæ¨æ–­æ ‡é¢˜: {filename}")
                        full_xml = ET.tostring(root, encoding='unicode')
                        logger.debug(f"å®Œæ•´XMLç»“æ„: {full_xml}")
                        return
            elif not title_elem.text or not title_elem.text.strip():
                logger.warning(f"NFOæ–‡ä»¶ä¸­titleå…ƒç´ å†…å®¹ä¸ºç©º: {nfo_path}")
                # å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„æ ‡é¢˜å…ƒç´ 
                alt_title_elem = None
                for title_tag in ["originaltitle", "sorttitle", "name", "showname"]:
                    alt_title_elem = self.find_elem_ignore_ns(root, title_tag)
                    if alt_title_elem is not None and alt_title_elem.text and alt_title_elem.text.strip():
                        logger.info(
                            f"ä½¿ç”¨æ›¿ä»£æ ‡é¢˜å…ƒç´  {title_tag}: {alt_title_elem.text}")
                        break
                if alt_title_elem and alt_title_elem.text and alt_title_elem.text.strip():
                    title_elem = alt_title_elem
                else:
                    logger.warning(
                        f"NFOæ–‡ä»¶titleå†…å®¹ä¸ºç©ºä¸”æ— æ›¿ä»£æ ‡é¢˜ï¼Œå°è¯•ä»æ–‡ä»¶åæ¨æ–­: {nfo_path}")
                    # ä»æ–‡ä»¶åæ¨æ–­æ ‡é¢˜
                    filename = nfo_path.stem  # å»æ‰æ‰©å±•å
                    import re
                    title_from_filename = re.sub(
                        r'\s*\(\d{4}\)\s*.*$', '', filename)
                    title_from_filename = re.sub(
                        r'\s*-\s*\d+p.*$', '', title_from_filename)
                    title_from_filename = re.sub(
                        r'\s*-\s*2160p.*$', '', title_from_filename)
                    title_from_filename = title_from_filename.strip()
                    if title_from_filename:
                        logger.info(
                            f"ä»æ–‡ä»¶åæ¨æ–­æ ‡é¢˜: {title_from_filename}")
                        title_elem = ET.Element("title")
                        title_elem.text = title_from_filename
                    else:
                        logger.warning(
                            f"æ— æ³•ä»æ–‡ä»¶åæ¨æ–­æ ‡é¢˜: {filename}")
                        return
            else:
                logger.debug(f"æ‰¾åˆ°titleå…ƒç´ : {title_elem.text}")

            title = title_elem.text.strip()
            if not title:
                logger.warning(f"NFOæ–‡ä»¶æ ‡é¢˜ä¸ºç©º: {nfo_path}")
                return
            logger.debug(f"æœ€ç»ˆä½¿ç”¨æ ‡é¢˜: {title}")

            # è·å–å¹´ä»½ï¼ˆå¿½ç•¥å‘½åç©ºé—´ï¼‰
            year = None
            year_elem = self.find_elem_ignore_ns(root, "year")
            if year_elem is None:
                logger.debug(f"NFOæ–‡ä»¶ä¸­æœªæ‰¾åˆ°yearå…ƒç´ ")
            elif not year_elem.text or not year_elem.text.strip():
                logger.debug(
                    f"NFOæ–‡ä»¶ä¸­yearå…ƒç´ å†…å®¹ä¸ºç©º: '{year_elem.text}'")
            else:
                try:
                    year = int(year_elem.text.strip())
                    logger.debug(f"æ‰¾åˆ°å¹´ä»½: {year}")
                except ValueError:
                    logger.warning(
                        f"å¹´ä»½æ ¼å¼æ— æ•ˆ: '{year_elem.text}'")

            # å¦‚æœä»XMLä¸­æ²¡æ‰¾åˆ°å¹´ä»½ï¼Œå°è¯•ä»æ–‡ä»¶åæ¨æ–­
            if not year:
                import re
                year_match = re.search(r'\((\d{4})\)', nfo_path.name)
                if year_match:
                    try:
                        year = int(year_match.group(1))
                        logger.info(f"ä»æ–‡ä»¶åæ¨æ–­å¹´ä»½: {year}")
                    except ValueError:
                        pass

            # ç”Ÿæˆåª’ä½“é”®
            media_key = self.get_media_key(title, year, media_type)
            logger.debug(f"ç”Ÿæˆåª’ä½“é”®: {media_key}")

            # å¤‡ä»½TMDBè¯„åˆ†
            self.backup_tmdb_rating(nfo_path, media_key)

            # æ ¹æ®è¯„åˆ†æºå¤„ç†
            if self._rating_source == "douban":
                # å…ˆæ£€æŸ¥æ˜¯å¦å¯ä»¥è·³è¿‡æ›´æ–°
                if self.should_skip_rating_update(nfo_path, self._rating_source):
                    logger.info(f"è·³è¿‡è¯„åˆ†æ›´æ–°: {nfo_path}")
                    # è®°å½•è·³è¿‡çš„ç»“æœ
                    self._skipped_results.append({
                        'title': title,
                        'reason': 'è·ç¦»ä¸Šæ¬¡æ›´æ–°æ—¶é—´è¿‡çŸ­',
                        'media_type': media_type.value
                    })
                else:
                    # æ£€æŸ¥NFOä¸­æ˜¯å¦å·²å­˜åœ¨æœ‰æ•ˆçš„è±†ç“£è¯„åˆ†
                    douban_rating = None
                    if self.is_existing_douban_rating_valid(nfo_path):
                        douban_rating = self.get_existing_douban_rating(nfo_path)
                        if douban_rating:
                            logger.info(f"ä½¿ç”¨NFOä¸­å·²å­˜åœ¨çš„è±†ç“£è¯„åˆ†: {title} = {douban_rating}")
                    
                    # å¦‚æœNFOä¸­æ²¡æœ‰æœ‰æ•ˆçš„è±†ç“£è¯„åˆ†ï¼Œåˆ™ä»ç½‘ç»œè·å–
                    if not douban_rating:
                        # æ ¹æ®åª’ä½“ç±»å‹è·å–è¯„åˆ†
                        if media_type == MediaType.TV:
                            # ç”µè§†å‰§ï¼šè·å–ç¬¬ä¸€å­£çš„è¯„åˆ†ä½œä¸ºæ•´ä¸ªå‰§é›†çš„è¯„åˆ†
                            douban_rating = self._get_first_season_rating(title, year)
                        else:
                            # ç”µå½±ï¼šç›´æ¥è·å–è±†ç“£è¯„åˆ†
                            douban_rating = self.get_douban_rating(title, year)

                    if douban_rating:
                        # æ›´æ–°NFOæ–‡ä»¶ï¼ˆè·³è¿‡å†…éƒ¨çš„è·³è¿‡æ£€æŸ¥ï¼Œå› ä¸ºå·²ç»æ£€æŸ¥è¿‡äº†ï¼‰
                        if self._update_nfo_rating_direct(nfo_path, douban_rating, "douban"):
                            # æ·»åŠ åˆ°å¤„ç†ç»“æœ
                            self._processing_results.append({
                                'title': title,
                                'rating': douban_rating,
                                'source': 'douban',
                                'media_type': media_type.value,
                                'file_path': str(nfo_path),
                                'directory_alias': directory_alias
                            })
                    else:
                        logger.warning(f"æ— æ³•è·å–è±†ç“£è¯„åˆ†: {title}")
                        # æ·»åŠ åˆ°å¤±è´¥ç»“æœ
                        self._failed_results.append({
                            'title': title,
                            'reason': 'æ— æ³•è·å–è±†ç“£è¯„åˆ†',
                            'media_type': media_type.value,
                            'file_path': str(nfo_path),
                            'directory_alias': directory_alias
                        })

            elif self._rating_source == "tmdb":
                # æ¢å¤TMDBè¯„åˆ†
                if media_key:
                    restored_rating = self.restore_tmdb_rating(
                        nfo_path, media_key)
                    if restored_rating is not None:
                        # æ·»åŠ åˆ°å¤„ç†ç»“æœ
                        if restored_rating == 0.0:
                            # åŸæœ¬å°±æ²¡æœ‰è¯„åˆ†ï¼ŒæˆåŠŸåˆ é™¤ratingæ ‡ç­¾
                            self._processing_results.append({
                                'title': title,
                                'rating': 'æ— è¯„åˆ†',
                                'source': 'tmdb',
                                'media_type': media_type.value,
                                'file_path': str(nfo_path),
                                'directory_alias': directory_alias
                            })
                        else:
                            # æˆåŠŸæ¢å¤è¯„åˆ†
                            self._processing_results.append({
                                'title': title,
                                'rating': restored_rating,
                                'source': 'tmdb',
                                'media_type': media_type.value,
                                'file_path': str(nfo_path),
                                'directory_alias': directory_alias
                            })
                    else:
                        # æ·»åŠ åˆ°å¤±è´¥ç»“æœ
                        self._failed_results.append({
                            'title': title,
                            'reason': 'æ— æ³•æ¢å¤TMDBè¯„åˆ†',
                            'media_type': media_type.value,
                            'file_path': str(nfo_path),
                            'directory_alias': directory_alias
                        })
                else:
                    logger.warning(f"æœªæ‰¾åˆ°TMDBè¯„åˆ†å¤‡ä»½: {title}")
                    # æ·»åŠ åˆ°å¤±è´¥ç»“æœ
                    self._failed_results.append({
                        'title': title,
                        'reason': 'æœªæ‰¾åˆ°TMDBè¯„åˆ†å¤‡ä»½',
                        'media_type': media_type.value,
                        'file_path': str(nfo_path),
                        'directory_alias': directory_alias
                    })
        except Exception as e:
            logger.error(f"å¤„ç†NFOæ–‡ä»¶å¤±è´¥ {nfo_path}: {str(e)}")
            # æ·»åŠ åˆ°å¤±è´¥ç»“æœ
            self._failed_results.append({
                'title': title if 'title' in locals() else str(nfo_path.stem),
                'reason': f'å¤„ç†å¼‚å¸¸: {str(e)}',
                'media_type': 'UNKNOWN',
                'file_path': str(nfo_path),
                'directory_alias': directory_alias
            })
            import traceback
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")

    def scrape_media_if_needed(self, media_path: Path, is_tv_show: bool = False,
                               target_media_file: Path = None) -> bool:
        """å¦‚æœéœ€è¦åˆ™è¿›è¡Œåˆ®å‰Š"""
        if not self._auto_scrape:
            return True

        try:
            # å¯¹äºç”µè§†å‰§ç›®å½•ï¼Œæ£€æŸ¥tvshow.nfoæ–‡ä»¶
            if is_tv_show:
                tvshow_nfo = media_path / "tvshow.nfo"
                if tvshow_nfo.exists():
                    logger.debug(f"ç”µè§†å‰§ç›®å½•å·²å­˜åœ¨tvshow.nfoæ–‡ä»¶: {media_path}")
                    return True
                else:
                    logger.info(f"ç”µè§†å‰§ç›®å½•ç¼ºå°‘tvshow.nfoï¼Œå¼€å§‹åˆ®å‰Š: {media_path}")
                    return self._scrape_directory(media_path)

            # å¦‚æœæŒ‡å®šäº†ç›®æ ‡åª’ä½“æ–‡ä»¶ï¼Œæ£€æŸ¥å¯¹åº”çš„NFOæ–‡ä»¶
            if target_media_file:
                target_nfo = target_media_file.with_suffix('.nfo')
                if target_nfo.exists():
                    logger.debug(f"NFOæ–‡ä»¶å·²å­˜åœ¨: {target_nfo}")
                    return True
                else:
                    logger.info(f"NFOæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼€å§‹åˆ®å‰Š: {target_media_file}")
                    return self._scrape_directory(target_media_file.parent)

            # é»˜è®¤åˆ®å‰Šæ•´ä¸ªç›®å½•
            return self._scrape_directory(media_path)

        except Exception as e:
            logger.error(f"åˆ®å‰Šå¤±è´¥ {media_path}: {str(e)}")
            return False

    def _scrape_directory(self, media_path: Path) -> bool:
        """åˆ®å‰Šç›®å½•"""
        try:
            logger.info(f"å¼€å§‹åˆ®å‰Šç›®å½•: {media_path}")

            # è°ƒç”¨MoviePilotçš„åˆ®å‰ŠåŠŸèƒ½
            mediachain = MediaChain()

            # åˆ›å»ºFileItem
            fileitem = FileItem(
                path=str(media_path),
                type="dir",
                storage="local"
            )

            # è¯†åˆ«åª’ä½“ä¿¡æ¯
            meta = MetaInfoPath(media_path)
            mediainfo = mediachain.recognize_media(meta)

            if mediainfo:
                # æ‰§è¡Œåˆ®å‰Š
                mediachain.scrape_metadata(
                    fileitem=fileitem, meta=meta, mediainfo=mediainfo, overwrite=True)
                logger.info(f"ç›®å½•åˆ®å‰Šå®Œæˆ: {media_path}")
                return True
            else:
                logger.warning(f"æ— æ³•è¯†åˆ«åª’ä½“ä¿¡æ¯: {media_path}")
                return False

        except Exception as e:
            logger.error(f"åˆ®å‰Šç›®å½•å¤±è´¥ {media_path}: {str(e)}")
            return False

    def restore_tmdb_rating(self, nfo_path: Path, media_key: str) -> Optional[float]:
        """ä»EmbyRatingæ ‡ç­¾æ¢å¤TMDBè¯„åˆ†ï¼Œè¿”å›æ¢å¤çš„è¯„åˆ†å€¼"""
        try:
            # è¯»å–åŸå§‹æ–‡ä»¶å†…å®¹
            try:
                with open(nfo_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                try:
                    with open(nfo_path, 'r', encoding='gbk') as f:
                        content = f.read()
                except UnicodeDecodeError:
                    logger.error(f"æ— æ³•è¯»å–NFOæ–‡ä»¶ç¼–ç : {nfo_path}")
                    return False

            # è§£æXML
            try:
                root = ET.fromstring(content)
            except ET.ParseError as e:
                logger.error(
                    f"XMLè§£æå¤±è´¥: {nfo_path}, é”™è¯¯: {str(e)}")
                return False

            # ä»EmbyRatingæ ‡ç­¾ä¸­è·å–TMDBè¯„åˆ†
            emby_rating_elem = root.find("EmbyRating")
            if emby_rating_elem is None:
                logger.warning(f"æœªæ‰¾åˆ°EmbyRatingæ ‡ç­¾: {media_key}")
                return None

            tmdb_elem = emby_rating_elem.find("tmdb")
            if tmdb_elem is None or not tmdb_elem.text:
                logger.warning(f"æœªæ‰¾åˆ°TMDBè¯„åˆ†å¤‡ä»½: {media_key}")
                # å¦‚æœæ²¡æœ‰å¤‡ä»½ï¼Œè®°å½•ä¸ºnoneï¼Œè¡¨ç¤ºåŸæœ¬å°±æ²¡æœ‰TMDBè¯„åˆ†
                if tmdb_elem is None:
                    tmdb_elem = ET.SubElement(emby_rating_elem, "tmdb")
                tmdb_elem.text = "none"
                logger.info(f"è®°å½•åŸNFOæ–‡ä»¶æ— TMDBè¯„åˆ†: {media_key}")

                # åˆ é™¤ratingæ ‡ç­¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                traditional_rating_elem = root.find("rating")
                if traditional_rating_elem is not None:
                    root.remove(traditional_rating_elem)
                    logger.debug(f"å·²åˆ é™¤ratingæ ‡ç­¾")

                # æ›´æ–°rating_sourceä¸ºtmdb
                rating_source_elem = emby_rating_elem.find("rating_source")
                if rating_source_elem is None:
                    rating_source_elem = ET.SubElement(emby_rating_elem, "rating_source")
                rating_source_elem.text = "tmdb"

                # ä¿å­˜æ–‡ä»¶
                try:
                    xml_str = self.format_xml(root)
                    with open(nfo_path, 'w', encoding='utf-8') as f:
                        f.write(xml_str)
                    logger.info(f"æ¢å¤TMDBçŠ¶æ€æˆåŠŸï¼ˆæ— è¯„åˆ†ï¼‰: {media_key}")
                    return 0.0
                except Exception as e:
                    logger.error(f"ä¿å­˜NFOæ–‡ä»¶å¤±è´¥: {nfo_path}, é”™è¯¯: {str(e)}")
                    return None

            # æ£€æŸ¥æ˜¯å¦ä¸º"none"ï¼Œè¡¨ç¤ºåŸæœ¬å°±æ²¡æœ‰è¯„åˆ†
            if tmdb_elem.text.strip().lower() == "none":
                logger.info(f"åŸNFOæ–‡ä»¶æ— è¯„åˆ†ï¼Œåˆ é™¤ratingæ ‡ç­¾: {media_key}")
                # åˆ é™¤ratingæ ‡ç­¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                traditional_rating_elem = root.find("rating")
                if traditional_rating_elem is not None:
                    root.remove(traditional_rating_elem)
                    logger.debug(f"å·²åˆ é™¤ratingæ ‡ç­¾")

                # æ›´æ–°rating_sourceä¸ºtmdb
                rating_source_elem = emby_rating_elem.find("rating_source")
                if rating_source_elem is None:
                    rating_source_elem = ET.SubElement(emby_rating_elem, "rating_source")
                rating_source_elem.text = "tmdb"

                return 0.0  # è¿”å›0è¡¨ç¤ºæˆåŠŸä½†æ— è¯„åˆ†

            # å°è¯•è§£æè¯„åˆ†
            try:
                rating = float(tmdb_elem.text)
            except ValueError:
                logger.error(f"TMDBè¯„åˆ†æ ¼å¼æ— æ•ˆ: {tmdb_elem.text}")
                return None

            # æ›´æ–°ä¼ ç»Ÿratingæ ‡ç­¾
            traditional_rating_elem = root.find("rating")
            if traditional_rating_elem is None:
                traditional_rating_elem = ET.SubElement(root, "rating")
            traditional_rating_elem.text = str(rating)

            # æ›´æ–°EmbyRatingæ ‡ç­¾ä¸­çš„rating_source
            rating_source_elem = emby_rating_elem.find("rating_source")
            if rating_source_elem is None:
                rating_source_elem = ET.SubElement(emby_rating_elem, "rating_source")
            rating_source_elem.text = "tmdb"

            # æ›´æ–°æ›´æ–°æ—¶é—´
            update_elem = emby_rating_elem.find("update")
            if update_elem is None:
                update_elem = ET.SubElement(emby_rating_elem, "update")
            update_elem.text = datetime.now().strftime("%Y-%m-%d")

            # æ ¼å¼åŒ–XMLå¹¶ç›´æ¥ä¿å­˜
            try:
                xml_str = self.format_xml(root)

                with open(nfo_path, 'w', encoding='utf-8') as f:
                    f.write(xml_str)

                if rating == 0.0:
                    logger.info(f"æ¢å¤TMDBçŠ¶æ€æˆåŠŸï¼ˆæ— è¯„åˆ†ï¼‰: {media_key}")
                else:
                    logger.info(f"æ¢å¤TMDBè¯„åˆ†æˆåŠŸ: {media_key} = {rating}")
                return rating

            except Exception as e:
                logger.error(
                    f"ä¿å­˜NFOæ–‡ä»¶å¤±è´¥: {nfo_path}, é”™è¯¯: {str(e)}")
                return None

        except Exception as e:
            logger.error(f"æ¢å¤TMDBè¯„åˆ†å¤±è´¥ {nfo_path}: {str(e)}")
            return None

    def _start_file_monitor(self):
        """å¯åŠ¨æ–‡ä»¶ç›‘æ§ï¼ˆå¼‚æ­¥ï¼‰"""
        if not self._media_dirs:
            logger.warning(f"æœªé…ç½®åª’ä½“ç›®å½•ï¼Œæ— æ³•å¯ç”¨æ–‡ä»¶ç›‘æ§")
            return

        # åœæ­¢ç°æœ‰çš„ç›‘æ§çº¿ç¨‹
        self._stop_monitor_thread()

        # åˆ›å»ºåœæ­¢äº‹ä»¶
        self._monitor_stop_event = threading.Event()

        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        self._monitor_thread = threading.Thread(
            target=self._monitor_thread_worker,
            name="EmbyRating-FileMonitor",
            daemon=True
        )
        self._monitor_thread.start()
        logger.info("æ–‡ä»¶ç›‘æ§çº¿ç¨‹å·²å¯åŠ¨")

    def _monitor_thread_worker(self):
        """ç›‘æ§çº¿ç¨‹å·¥ä½œå‡½æ•°"""
        try:
            logger.info("æ–‡ä»¶ç›‘æ§çº¿ç¨‹å¼€å§‹å·¥ä½œ")

            # åœæ­¢ç°æœ‰çš„ç›‘æ§
            self._stop_file_monitor()

            # è§£æåª’ä½“ç›®å½•
            media_dirs = [d.strip() for d in self._media_dirs.split("\n") if d.strip()]
            logger.info(f"å‡†å¤‡å¯åŠ¨æ–‡ä»¶ç›‘æ§ï¼Œå…± {len(media_dirs)} ä¸ªç›®å½•")

            # ä¸ºæ¯ä¸ªç›®å½•å¯åŠ¨ç›‘æ§
            for dir_config in media_dirs:
                # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°åœæ­¢ä¿¡å·
                if self._monitor_stop_event and self._monitor_stop_event.is_set():
                    logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œä¸­æ–­æ–‡ä»¶ç›‘æ§å¯åŠ¨")
                    break

                if not dir_config:
                    continue

                try:
                    # è§£æç›®å½•è·¯å¾„
                    if "#" in dir_config:
                        mon_path = dir_config.split("#", 1)[0].strip()
                    else:
                        mon_path = dir_config.strip()

                    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
                    if not Path(mon_path).exists():
                        logger.warning(f"ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡: {mon_path}")
                        continue

                    logger.debug(f"æ­£åœ¨ä¸ºç›®å½• {mon_path} åˆ›å»ºæ–‡ä»¶ç›‘æ§...")
                    # å¯ä»¥æ ¹æ®éœ€è¦å¼ºåˆ¶ä½¿ç”¨è½®è¯¢æ¨¡å¼ï¼Œé€‚ç”¨äºæœ‰å¤§é‡è½¯è¿æ¥çš„ç›®å½•
                    observer = self.__choose_observer(force_polling=False)

                    # å…ˆæ·»åŠ åˆ°åˆ—è¡¨ï¼Œå³ä½¿åç»­å¤±è´¥ä¹Ÿèƒ½åœ¨åœæ­¢æ—¶æ¸…ç†
                    self._file_observers.append(observer)

                    # è®¾ç½®ç›‘æ§ï¼Œéé€’å½’æ¨¡å¼é¿å…è½¯è¿æ¥æ€§èƒ½é—®é¢˜
                    observer.schedule(
                        NFOFileHandler(self),
                        mon_path,
                        recursive=True
                    )

                    observer.daemon = True

                    # å¯åŠ¨observerï¼Œè¿™é‡Œå¯èƒ½ä¼šé˜»å¡
                    logger.debug(f"æ­£åœ¨å¯åŠ¨ {mon_path} çš„æ–‡ä»¶ç›‘æ§æœåŠ¡...")
                    observer.start()

                    # ç®€å•éªŒè¯observeræ˜¯å¦æˆåŠŸå¯åŠ¨
                    if hasattr(observer, 'is_alive') and observer.is_alive():
                        logger.info(f"{mon_path} çš„æ–‡ä»¶ç›‘æ§æœåŠ¡å¯åŠ¨æˆåŠŸ")
                    else:
                        logger.warning(f"{mon_path} çš„æ–‡ä»¶ç›‘æ§æœåŠ¡å¯åŠ¨åçŠ¶æ€å¼‚å¸¸")

                except Exception as e:
                    logger.error(f"{mon_path} å¯åŠ¨æ–‡ä»¶ç›‘æ§å¤±è´¥ï¼š{str(e)}")
                    # å¦‚æœå¯åŠ¨å¤±è´¥ï¼Œå°è¯•ä»åˆ—è¡¨ä¸­ç§»é™¤è¿™ä¸ªobserver
                    if 'observer' in locals() and observer in self._file_observers:
                        try:
                            self._file_observers.remove(observer)
                            observer.stop()
                            # åªæœ‰åœ¨observerå·²å¯åŠ¨çš„æƒ…å†µä¸‹æ‰è°ƒç”¨join
                            if hasattr(observer, 'is_alive') and observer.is_alive():
                                observer.join()
                        except:
                            pass

            logger.info(f"æ–‡ä»¶ç›‘æ§å¯åŠ¨å®Œæˆ")

        except Exception as e:
            logger.error(f"ç›‘æ§çº¿ç¨‹å·¥ä½œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        finally:
            logger.info("æ–‡ä»¶ç›‘æ§çº¿ç¨‹å·¥ä½œç»“æŸ")


    def _stop_file_monitor(self):
        """åœæ­¢æ–‡ä»¶ç›‘æ§"""
        # é¦–å…ˆåœæ­¢æ–‡ä»¶ç›‘æ§ï¼Œé˜²æ­¢æ–°çš„åˆ é™¤äº‹ä»¶
        if self._file_observers:
            for observer in self._file_observers:
                try:
                    observer.stop()
                    # åªæœ‰åœ¨observerå·²å¯åŠ¨çš„æƒ…å†µä¸‹æ‰è°ƒç”¨join
                    if hasattr(observer, 'is_alive') and observer.is_alive():
                        observer.join()
                except Exception as e:
                    print(str(e))
                    logger.error(f"åœæ­¢ç›®å½•ç›‘æ§å¤±è´¥ï¼š{str(e)}")
        self._file_observers = []
        logger.debug("æ–‡ä»¶ç›‘æ§å·²åœæ­¢")

    def _handle_new_nfo_file(self, nfo_path: Path):
        """å¤„ç†æ–°åˆ›å»ºçš„NFOæ–‡ä»¶"""
        try:
            logger.info(f"å¤„ç†æ–°NFOæ–‡ä»¶: {nfo_path}")

            # ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆ
            time.sleep(2)

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä»ç„¶å­˜åœ¨
            if not nfo_path.exists():
                logger.debug(f"NFOæ–‡ä»¶å·²ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†: {nfo_path}")
                return

            # åˆ¤æ–­NFOæ–‡ä»¶ç±»å‹
            media_type = self._determine_nfo_type(nfo_path)
            if not media_type:
                logger.debug(f"æ— æ³•ç¡®å®šNFOæ–‡ä»¶ç±»å‹æˆ–ä¸éœ€è¦å¤„ç†: {nfo_path}")
                return

            # æ£€æŸ¥è¯„åˆ†æºé…ç½®
            if self._rating_source == "tmdb":
                logger.debug(f"å½“å‰è¯„åˆ†æºä¸ºTMDBï¼Œè·³è¿‡å¤„ç†: {nfo_path}")
                return

            # æ ¹æ®åª’ä½“ç±»å‹å¤„ç†
            if media_type == "movie":
                self._handle_movie_nfo(nfo_path)
            elif media_type == "tvshow":
                self._handle_tvshow_nfo(nfo_path)

        except Exception as e:
            logger.error(f"å¤„ç†NFOæ–‡ä»¶å¤±è´¥ {nfo_path}: {str(e)}")
            import traceback
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")

    def _determine_nfo_type(self, nfo_path: Path) -> Optional[str]:
        """åˆ¤æ–­NFOæ–‡ä»¶ç±»å‹"""
        try:
            # è¯»å–NFOæ–‡ä»¶å†…å®¹
            try:
                with open(nfo_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                try:
                    with open(nfo_path, 'r', encoding='gbk') as f:
                        content = f.read()
                except UnicodeDecodeError:
                    logger.debug(f"æ— æ³•è¯»å–NFOæ–‡ä»¶ç¼–ç : {nfo_path}")
                    return None

            # è§£æXML
            try:
                root = ET.fromstring(content)
            except ET.ParseError as e:
                logger.debug(f"XMLè§£æå¤±è´¥: {nfo_path}, é”™è¯¯: {str(e)}")
                return None

            # æ ¹æ®æ ¹å…ƒç´ åˆ¤æ–­ç±»å‹
            root_tag = root.tag.lower()
            if root_tag == "movie":
                return "movie"
            elif root_tag == "tvshow":
                return "tvshow"
            elif root_tag == "episodedetails":
                # ç”µè§†å‰§é›†æ•°ï¼Œè·³è¿‡å¤„ç†
                logger.debug(f"æ£€æµ‹åˆ°å‰§é›†NFOæ–‡ä»¶ï¼Œè·³è¿‡å¤„ç†: {nfo_path}")
                return None
            else:
                logger.debug(f"æœªçŸ¥çš„NFOæ–‡ä»¶ç±»å‹: {root_tag}, æ–‡ä»¶: {nfo_path}")
                return None

        except Exception as e:
            logger.error(f"åˆ¤æ–­NFOæ–‡ä»¶ç±»å‹å¤±è´¥ {nfo_path}: {str(e)}")
            return None

    def _handle_movie_nfo(self, nfo_path: Path):
        """å¤„ç†ç”µå½±NFOæ–‡ä»¶"""
        try:
            logger.info(f"å¤„ç†ç”µå½±NFOæ–‡ä»¶: {nfo_path}")

            # è°ƒç”¨ç°æœ‰çš„ç”µå½±å¤„ç†æ–¹æ³•
            self.process_nfo_file(nfo_path, MediaType.MOVIE)

            # å‘é€å•ä¸ªæ–‡ä»¶çš„é€šçŸ¥
            self._send_single_file_notification()

        except Exception as e:
            logger.error(f"å¤„ç†ç”µå½±NFOæ–‡ä»¶å¤±è´¥ {nfo_path}: {str(e)}")

    def _handle_tvshow_nfo(self, nfo_path: Path):
        """å¤„ç†ç”µè§†å‰§NFOæ–‡ä»¶"""
        try:
            logger.info(f"å¤„ç†ç”µè§†å‰§NFOæ–‡ä»¶: {nfo_path}")

            self.process_nfo_file(nfo_path, MediaType.TV)

            # å‘é€å•ä¸ªæ–‡ä»¶çš„é€šçŸ¥
            self._send_single_file_notification()

        except Exception as e:
            logger.error(f"å¤„ç†ç”µè§†å‰§NFOæ–‡ä»¶å¤±è´¥ {nfo_path}: {str(e)}")

    def _send_single_file_notification(self):
        """å‘é€å•ä¸ªæ–‡ä»¶å¤„ç†çš„é€šçŸ¥"""
        try:
            # ç»Ÿè®¡å¤„ç†ç»“æœ
            success_count = len(self._processing_results)
            failed_count = len(self._failed_results)
            skipped_count = len(self._skipped_results)
            total_count = success_count + failed_count + skipped_count

            if total_count == 0:
                return

            # æ„å»ºç®€åŒ–çš„é€šçŸ¥å†…å®¹
            if success_count > 0:
                result = self._processing_results[0]
                title = "ğŸ¬ æ–‡ä»¶ç›‘æ§ - è¯„åˆ†æ›´æ–°æˆåŠŸ"
                text = f"âœ… {result['title']}\nğŸ“ˆ è¯„åˆ†: {result['rating']} ({result['source']})"
            elif skipped_count > 0:
                result = self._skipped_results[0]
                title = "ğŸ¬ æ–‡ä»¶ç›‘æ§ - è·³è¿‡æ›´æ–°"
                text = f"â­ï¸ {result['title']}\nğŸ’¡ åŸå› : {result['reason']}"
            else:
                result = self._failed_results[0]
                title = "ğŸ¬ æ–‡ä»¶ç›‘æ§ - æ›´æ–°å¤±è´¥"
                text = f"âŒ {result['title']}\nğŸ’¡ åŸå› : {result['reason']}"

            # å‘é€é€šçŸ¥
            if self._notify:
                self.post_message(
                    mtype=NotificationType.Plugin,
                    title=title,
                    text=text
                )

        except Exception as e:
            logger.error(f"å‘é€æ–‡ä»¶ç›‘æ§é€šçŸ¥å¤±è´¥: {str(e)}")
        finally:
            # ä¿å­˜å¤„ç†ç»“æœåˆ°å†å²è®°å½•ï¼ˆä¸ä¿å­˜è·³è¿‡çš„è®°å½•ï¼‰
            for result in self._processing_results:
                self._add_success_record(
                    result['title'],
                    result['rating'],
                    result['source'],
                    result['media_type'],
                    result.get('file_path'),
                    result.get('directory_alias')
                )

            for result in self._failed_results:
                self._add_failed_record(
                    result['title'],
                    result['reason'],
                    result['media_type'],
                    result.get('file_path'),
                    result.get('directory_alias')
                )

            # è·³è¿‡çš„è®°å½•ä¸å†ä¿å­˜åˆ°å†å²è®°å½•ä¸­
            # for result in self._skipped_results:
            #     self._add_skipped_record(
            #         result['title'],
            #         result['reason'],
            #         result['media_type']
            #     )

            # æ¸…ç©ºç»“æœåˆ—è¡¨
            self._processing_results.clear()
            self._failed_results.clear()
            self._skipped_results.clear()
